{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41d3fa6-0ae0-490d-a02b-0dbf81799488",
   "metadata": {},
   "source": [
    "# Quantum benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6011e42-1fab-4f9f-ab99-f4f08607517e",
   "metadata": {},
   "source": [
    "## I - Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4f6b4-240b-4b7f-abe4-4e74b3b8cc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5492ce-4f08-4755-b4c2-efd698139101",
   "metadata": {},
   "source": [
    "## II - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90371200-0133-46ab-a205-d0f6b8858e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "#Import classical libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import functools\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "import logging\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4552ad2-d5ac-4904-8e45-eafa355e4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598c94c-fdcf-41cd-a4ea-e262932c7e0f",
   "metadata": {},
   "source": [
    "## III - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e683f3b5-6021-4eb7-bc53-539a5cd79bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out CSV\n",
    "\n",
    "df = pd.read_csv('fraud_detection_bank_dataset.csv', sep=',')\n",
    "df = df.sample(1400)\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df_labels = df['targets']\n",
    "df.drop(['targets'],axis = 1,inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "cols = ['col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_18', 'col_19','col_20', 'col_21', 'col_35', \n",
    "        'col_51', 'col_52', 'col_53', 'col_70','col_71','col_7', 'col_22', 'col_54', 'col_56']\n",
    "\n",
    "X_train = X_train.drop(cols, axis=1)\n",
    "X_test = X_test.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10255383-ae13-42c1-8d19-b5cf9eca4d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 112)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf69c7f1-b10e-4b54-89ec-89dd5829ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "#EDA using Autoviz\n",
    "sweet_report = sv.analyze(df)\n",
    "\n",
    "#Saving results to HTML file\n",
    "sweet_report.show_html('sweet_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff48fa-d03b-435d-9343-67186c068b34",
   "metadata": {},
   "source": [
    "## IV - Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe1bb7-d7eb-412b-a291-bbeb654766f5",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1251e3e-c8ed-4e57-a790-1fa8003f8c31",
   "metadata": {},
   "source": [
    "## Quantum Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b4f425-f8b1-40b4-8c3f-4502a9a01a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a948c1c2-cb55-49b2-bb4c-c2d2fdca527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_1 = LDA(n_components=1)\n",
    "lda_2 = LDA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b921a949-e3bd-45b6-b0e0-a84f96788811",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_1.fit(X_train.iloc[:, :46], y_train)\n",
    "feature_1 = lda_1.transform(X_train.iloc[:, :46])\n",
    "lda_2.fit(X_train.iloc[:, 46:], y_train)\n",
    "feature_2 = lda_2.transform(X_train.iloc[:, 46:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333f641b-b9b7-498d-9b52-26f2fac93938",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = lda_1.transform(X_test.iloc[:, :46])\n",
    "test_2 = lda_2.transform(X_test.iloc[:, 46:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05a6064-c96b-4446-8da3-d160af9592bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_lda_1 = pd.DataFrame(feature_1)\n",
    "features_lda_2 = pd.DataFrame(feature_2)\n",
    "features_lda = features_lda_1.join(features_lda_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32050d4-fbc7-4ab4-ba40-f3a56ae6dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lda_1 =pd.DataFrame(test_1)\n",
    "test_lda_2 =pd.DataFrame(test_2)\n",
    "test_lda = test_lda_1.join(test_lda_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1de5099-55d4-4d2d-9ea4-eaf60c27b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = len(features_lda.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd626d5c-ff6a-443a-9700-10a93c24dc74",
   "metadata": {},
   "source": [
    "## Split train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afaf0912-bdbf-4460-ae4c-43016d1f5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "#sample_train, sample_test, label_train, label_test = train_test_split(\n",
    "#     features_lda, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "sample_train = features_lda.to_numpy()\n",
    "sample_test = test_lda.to_numpy()\n",
    "label_train = y_train\n",
    "label_test = y_test\n",
    "# Normalize\n",
    "\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Scale for better fit within the feature map\n",
    "\n",
    "#samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(sample_train)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Select a sample for a better control of the research and wall time\n",
    "\n",
    "\n",
    "#test_size = 200 #40\n",
    "#sample_test = sample_test[:test_size]\n",
    "#label_test = label_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d815edbe-c5e7-42d6-9489-39ebb940cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters for hybrid model\n",
    "\n",
    "seed = 8500\n",
    "feature_dim = n_dim\n",
    "num_reps = 2\n",
    "num_shots =256 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bc9af-4a1c-453d-be99-d54b9e045628",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ce7078-9255-4913-b6aa-7f05a0e077c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature_map\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=num_reps)\n",
    "\n",
    "# Define the backend\n",
    "backend = QuantumInstance(\n",
    "    BasicAer.get_backend(\"qasm_simulator\"), shots=num_shots, seed_simulator=seed, seed_transpiler=seed\n",
    ")\n",
    "\n",
    "# Define the kernel\n",
    "\n",
    "kernel = QuantumKernel(feature_map=feature_map, quantum_instance=backend)\n",
    "\n",
    "# Model run\n",
    "svc = SVC(kernel=kernel.evaluate)\n",
    "#svc.fit(sample_train, label_train)\n",
    "#score = svc.score(sample_test, label_test)\n",
    "\n",
    "#print(f\"Callable kernel classification test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8fd86d8-bec9-42ac-8543-c69c973a7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_predict = svc.predict(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee71fc2a-46dc-46d1-8f51-8e3df5723407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(label_test,result_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c063aa2-2125-47a9-adf1-ac7f53444551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from tqdm import tqdm\n",
    "def evaluate_ml_model(_models, X, y, n_fold=10, metric='precision'):\n",
    "    ''' Function to evaluate a ML and QML model with a list of metrics\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    results = pd.DataFrame()\n",
    "    kfold = KFold(n_splits=n_fold)\n",
    "    columns = []\n",
    "    for name, model in tqdm(_models):\n",
    "        # -------------------\n",
    "        # Variables initialization \n",
    "        _df = pd.DataFrame()\n",
    "        names = []\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        # -------------------\n",
    "        # k-fold Cross validation\n",
    "        cv_results = cross_validate(model, X, y, cv=kfold, scoring=metric)\n",
    "        \n",
    "        # -------------------\n",
    "        # Compute the mean and standard deviation \n",
    "        for _name, _array in cv_results.items():\n",
    "            names.append(_name)\n",
    "            means.append(round(100*_array.mean(), 2))\n",
    "            stds.append(round(100*_array.std(), 2))\n",
    "        # -------------------\n",
    "        # Save the results in a dataframe \n",
    "        _df =  pd.DataFrame([means, stds], columns=names)\n",
    "        columns.extend([name+' mean (%)', name+' std (%)'])\n",
    "        #results = results.join(_df, on=_df.index)\n",
    "        results = results.append(_df)\n",
    "    results.index = columns\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627ebe0d-8690-41ec-af85-590018084cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "#models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC()))\n",
    "models.append(('qsvc', svc))\n",
    "_metrics = ['precision', 'recall', 'f1', 'accuracy',  'matthews_corrcoef','balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea8ce2a3-7a80-42fb-aa8a-80a8da10941a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 1/1 [1:44:00<00:00, 6240.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fit_time  score_time  test_precision  test_recall  test_f1  \\\n",
      "qsvc mean (%)  51786.78    10619.15           82.35        65.92    72.93   \n",
      "qsvc std (%)    2383.02      412.76           10.29         8.79     8.14   \n",
      "\n",
      "               test_accuracy  test_matthews_corrcoef  test_balanced_accuracy  \n",
      "qsvc mean (%)          88.12                   66.35                   80.67  \n",
      "qsvc std (%)            3.02                    9.90                    4.94  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_matthews_corrcoef</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qsvc mean (%)</th>\n",
       "      <td>51786.78</td>\n",
       "      <td>10619.15</td>\n",
       "      <td>82.35</td>\n",
       "      <td>65.92</td>\n",
       "      <td>72.93</td>\n",
       "      <td>88.12</td>\n",
       "      <td>66.35</td>\n",
       "      <td>80.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsvc std (%)</th>\n",
       "      <td>2383.02</td>\n",
       "      <td>412.76</td>\n",
       "      <td>10.29</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.14</td>\n",
       "      <td>3.02</td>\n",
       "      <td>9.90</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fit_time  score_time  test_precision  test_recall  test_f1  \\\n",
       "qsvc mean (%)  51786.78    10619.15           82.35        65.92    72.93   \n",
       "qsvc std (%)    2383.02      412.76           10.29         8.79     8.14   \n",
       "\n",
       "               test_accuracy  test_matthews_corrcoef  test_balanced_accuracy  \n",
       "qsvc mean (%)          88.12                   66.35                   80.67  \n",
       "qsvc std (%)            3.02                    9.90                    4.94  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results = evaluate_ml_model(models, sample_train, label_train, n_fold=10, metric=_metrics)\n",
    "df_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77a5dd53-d18a-4b66-963f-5fab1974ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qsvc & 82.35 (10.29) & 65.92 (8.79) &  72.93 (8.14) & 66.35 (9.9) & 80.67 (4.94) \\\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in range(int(len(df_results.index)/2)):\n",
    "\n",
    "    print(f'{df_results.iloc[j].name.split()[0]} & {df_results.iloc[j][2]} ({df_results.iloc[j+1][2]}) & {df_results.iloc[j][3]} ({df_results.iloc[j+1][3]}) &  {df_results.iloc[j][4]} ({df_results.iloc[j+1][4]}) & {df_results.iloc[j][6]} ({df_results.iloc[j+1][6]}) & {df_results.iloc[j][7]} ({df_results.iloc[j+1][7]}) \\\\')\n",
    "    \n",
    "    j+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e6bd91-093f-415f-89b0-40e71ab48126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('LDA_fraud_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70b837-4e39-4b65-83ca-8e82fc83efa1",
   "metadata": {},
   "source": [
    "## Pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1d5656-f2f2-4d96-b210-a75a161cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ec49f5-c401-4c36-aae3-57aad3eaa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = n_dim\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffcf8fdb-37a0-4b64-b73c-76be553995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "#print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49568595-37ec-4749-a230-dc4c6dae2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08669908, requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, sample_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4febb380-0955-4f05-a872-326cc4e3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c16a1f84-63e5-4fbb-a647-cba6db4c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07412a53-c93b-4c73-bd0b-e7e144454435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bf0b58e-38f3-4c45-a4d2-3d69af787ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ff4aa6-c15b-4a59-a718-67d8da2402dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(0.25351439, requires_grad=True), tensor(0.30771751, requires_grad=True)], Y =  1\n",
      "X = [tensor(-0.14112155, requires_grad=True), tensor(-0.59942875, requires_grad=True)], Y = -1\n",
      "X = [tensor(0.01882312, requires_grad=True), tensor(-0.26478299, requires_grad=True)], Y = -1\n",
      "X = [tensor(0.20482344, requires_grad=True), tensor(-0.36680751, requires_grad=True)], Y =  1\n",
      "X = [tensor(-0.11257209, requires_grad=True), tensor(-0.59058478, requires_grad=True)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(label_train * 2 - np.ones(len(label_train)),requires_grad=True)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(sample_train, requires_grad=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "074f578a-1984-4814-9070-7b20063c8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e0005-464d-46c0-86f4-946291d7586c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d31d6a7-74f4-4e63-b1cb-b92bfb610a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.7344644 | f1: 0.7973214 \n",
      "Iter:     2 | Cost: 0.6157621 | f1: 0.7651786 \n",
      "Iter:     3 | Cost: 0.5747764 | f1: 0.7660714 \n",
      "Iter:     4 | Cost: 0.5470359 | f1: 0.7750000 \n",
      "New best\n",
      "Iter:     5 | Cost: 0.4855538 | f1: 0.8410714 \n",
      "New best\n",
      "Iter:     6 | Cost: 0.4756260 | f1: 0.8687500 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.5005733 | f1: 0.8776786 \n",
      "Iter:     8 | Cost: 0.4820430 | f1: 0.8741071 \n",
      "Iter:     9 | Cost: 0.4734429 | f1: 0.8714286 \n",
      "Iter:    10 | Cost: 0.4764574 | f1: 0.8723214 \n",
      "Iter:    11 | Cost: 0.4812747 | f1: 0.8741071 \n",
      "Iter:    12 | Cost: 0.4950626 | f1: 0.8767857 \n",
      "New best\n",
      "Iter:    13 | Cost: 0.5177490 | f1: 0.8830357 \n",
      "Iter:    14 | Cost: 0.5121669 | f1: 0.8785714 \n",
      "Iter:    15 | Cost: 0.5206429 | f1: 0.8812500 \n",
      "Iter:    16 | Cost: 0.5131106 | f1: 0.8776786 \n",
      "Iter:    17 | Cost: 0.4936372 | f1: 0.8723214 \n",
      "Iter:    18 | Cost: 0.4612667 | f1: 0.8616071 \n",
      "Iter:    19 | Cost: 0.4721951 | f1: 0.8392857 \n",
      "Iter:    20 | Cost: 0.4947040 | f1: 0.8178571 \n",
      "Iter:    21 | Cost: 0.4832185 | f1: 0.8321429 \n",
      "Iter:    22 | Cost: 0.4662176 | f1: 0.8464286 \n",
      "Iter:    23 | Cost: 0.4564663 | f1: 0.8598214 \n",
      "Iter:    24 | Cost: 0.4578867 | f1: 0.8633929 \n",
      "Iter:    25 | Cost: 0.4826984 | f1: 0.8714286 \n",
      "New best\n",
      "Iter:    26 | Cost: 0.5295364 | f1: 0.8866071 \n",
      "New best\n",
      "Iter:    27 | Cost: 0.5616951 | f1: 0.8875000 \n",
      "Iter:    28 | Cost: 0.5815431 | f1: 0.8857143 \n",
      "New best\n",
      "Iter:    29 | Cost: 0.5376531 | f1: 0.8875000 \n",
      "Iter:    30 | Cost: 0.4842260 | f1: 0.8758929 \n",
      "Iter:    31 | Cost: 0.4480919 | f1: 0.8616071 \n",
      "Iter:    32 | Cost: 0.4591067 | f1: 0.8508929 \n",
      "Iter:    33 | Cost: 0.4893036 | f1: 0.8303571 \n",
      "Iter:    34 | Cost: 0.4865860 | f1: 0.8330357 \n",
      "Iter:    35 | Cost: 0.4712550 | f1: 0.8437500 \n",
      "Iter:    36 | Cost: 0.4669343 | f1: 0.8473214 \n",
      "Iter:    37 | Cost: 0.4775980 | f1: 0.8392857 \n",
      "Iter:    38 | Cost: 0.4743403 | f1: 0.8419643 \n",
      "Iter:    39 | Cost: 0.4596727 | f1: 0.8517857 \n",
      "Iter:    40 | Cost: 0.4504086 | f1: 0.8642857 \n",
      "Iter:    41 | Cost: 0.4552588 | f1: 0.8651786 \n",
      "Iter:    42 | Cost: 0.4695406 | f1: 0.8696429 \n",
      "Iter:    43 | Cost: 0.4808690 | f1: 0.8741071 \n",
      "Iter:    44 | Cost: 0.4978699 | f1: 0.8812500 \n",
      "Iter:    45 | Cost: 0.4934848 | f1: 0.8803571 \n",
      "Iter:    46 | Cost: 0.4780744 | f1: 0.8723214 \n",
      "Iter:    47 | Cost: 0.4542214 | f1: 0.8669643 \n",
      "Iter:    48 | Cost: 0.4589712 | f1: 0.8553571 \n",
      "Iter:    49 | Cost: 0.4831829 | f1: 0.8285714 \n",
      "Iter:    50 | Cost: 0.5100123 | f1: 0.8053571 \n",
      "Iter:    51 | Cost: 0.5375884 | f1: 0.7857143 \n",
      "Iter:    52 | Cost: 0.5387457 | f1: 0.7857143 \n",
      "Iter:    53 | Cost: 0.5252551 | f1: 0.7892857 \n",
      "Iter:    54 | Cost: 0.5290839 | f1: 0.7857143 \n",
      "Iter:    55 | Cost: 0.5265037 | f1: 0.7866071 \n",
      "Iter:    56 | Cost: 0.4936986 | f1: 0.8116071 \n",
      "Iter:    57 | Cost: 0.4724958 | f1: 0.8500000 \n",
      "Iter:    58 | Cost: 0.4744619 | f1: 0.8669643 \n",
      "Iter:    59 | Cost: 0.5387063 | f1: 0.8821429 \n",
      "New best\n",
      "Iter:    60 | Cost: 0.6418568 | f1: 0.8901786 \n",
      "Iter:    61 | Cost: 0.6009089 | f1: 0.8883929 \n",
      "Iter:    62 | Cost: 0.5124914 | f1: 0.8642857 \n",
      "Iter:    63 | Cost: 0.5117925 | f1: 0.8366071 \n",
      "Iter:    64 | Cost: 0.5141059 | f1: 0.8625000 \n",
      "Iter:    65 | Cost: 0.5047415 | f1: 0.8642857 \n",
      "Iter:    66 | Cost: 0.4811183 | f1: 0.8616071 \n",
      "Iter:    67 | Cost: 0.4895674 | f1: 0.8348214 \n",
      "Iter:    68 | Cost: 0.5104171 | f1: 0.8116071 \n",
      "Iter:    69 | Cost: 0.5216499 | f1: 0.8080357 \n",
      "Iter:    70 | Cost: 0.4819035 | f1: 0.8321429 \n",
      "Iter:    71 | Cost: 0.4819374 | f1: 0.8303571 \n",
      "Iter:    72 | Cost: 0.4792729 | f1: 0.8330357 \n",
      "Iter:    73 | Cost: 0.4678243 | f1: 0.8544643 \n",
      "Iter:    74 | Cost: 0.5405874 | f1: 0.8696429 \n",
      "Iter:    75 | Cost: 0.6484834 | f1: 0.8883929 \n",
      "Iter:    76 | Cost: 0.5940117 | f1: 0.8812500 \n",
      "Iter:    77 | Cost: 0.5559936 | f1: 0.8767857 \n",
      "Iter:    78 | Cost: 0.5765359 | f1: 0.8839286 \n",
      "Iter:    79 | Cost: 0.4728569 | f1: 0.8678571 \n",
      "Iter:    80 | Cost: 0.4549123 | f1: 0.8660714 \n",
      "Iter:    81 | Cost: 0.4525705 | f1: 0.8625000 \n",
      "Iter:    82 | Cost: 0.4605594 | f1: 0.8535714 \n",
      "Iter:    83 | Cost: 0.4721654 | f1: 0.8464286 \n",
      "Iter:    84 | Cost: 0.4753030 | f1: 0.8464286 \n",
      "Iter:    85 | Cost: 0.4737489 | f1: 0.8491071 \n",
      "Iter:    86 | Cost: 0.4699454 | f1: 0.8562500 \n",
      "Iter:    87 | Cost: 0.4651103 | f1: 0.8571429 \n",
      "Iter:    88 | Cost: 0.4679235 | f1: 0.8473214 \n",
      "Iter:    89 | Cost: 0.5035498 | f1: 0.8142857 \n",
      "Iter:    90 | Cost: 0.5954386 | f1: 0.7767857 \n",
      "Iter:    91 | Cost: 0.5878727 | f1: 0.7767857 \n",
      "Iter:    92 | Cost: 0.5358645 | f1: 0.7937500 \n",
      "Iter:    93 | Cost: 0.4821720 | f1: 0.8276786 \n",
      "Iter:    94 | Cost: 0.4596855 | f1: 0.8660714 \n",
      "Iter:    95 | Cost: 0.4930825 | f1: 0.8705357 \n",
      "Iter:    96 | Cost: 0.5227551 | f1: 0.8741071 \n",
      "Iter:    97 | Cost: 0.5491582 | f1: 0.8776786 \n",
      "Iter:    98 | Cost: 0.5068060 | f1: 0.8687500 \n",
      "Iter:    99 | Cost: 0.4931047 | f1: 0.8205357 \n",
      "Iter:   100 | Cost: 0.5595117 | f1: 0.7696429 \n",
      "Iter:   101 | Cost: 0.5564511 | f1: 0.7758929 \n",
      "Iter:   102 | Cost: 0.5354416 | f1: 0.7883929 \n",
      "Iter:   103 | Cost: 0.5013616 | f1: 0.8133929 \n",
      "Iter:   104 | Cost: 0.4611086 | f1: 0.8526786 \n",
      "Iter:   105 | Cost: 0.4542911 | f1: 0.8669643 \n",
      "Iter:   106 | Cost: 0.4616843 | f1: 0.8660714 \n",
      "Iter:   107 | Cost: 0.4647533 | f1: 0.8669643 \n",
      "Iter:   108 | Cost: 0.4577004 | f1: 0.8678571 \n",
      "Iter:   109 | Cost: 0.4598009 | f1: 0.8553571 \n",
      "Iter:   110 | Cost: 0.4652077 | f1: 0.8500000 \n",
      "Iter:   111 | Cost: 0.4884027 | f1: 0.8205357 \n",
      "Iter:   112 | Cost: 0.5103759 | f1: 0.8044643 \n",
      "Iter:   113 | Cost: 0.4947854 | f1: 0.8125000 \n",
      "Iter:   114 | Cost: 0.4843689 | f1: 0.8258929 \n",
      "Iter:   115 | Cost: 0.4791599 | f1: 0.8303571 \n",
      "Iter:   116 | Cost: 0.4647837 | f1: 0.8526786 \n",
      "Iter:   117 | Cost: 0.4672253 | f1: 0.8687500 \n",
      "Iter:   118 | Cost: 0.4865677 | f1: 0.8714286 \n",
      "Iter:   119 | Cost: 0.4993069 | f1: 0.8767857 \n",
      "Iter:   120 | Cost: 0.5244339 | f1: 0.8821429 \n",
      "Iter:   121 | Cost: 0.5170218 | f1: 0.8830357 \n",
      "Iter:   122 | Cost: 0.5197424 | f1: 0.8821429 \n",
      "Iter:   123 | Cost: 0.5054598 | f1: 0.8794643 \n",
      "Iter:   124 | Cost: 0.4814579 | f1: 0.8750000 \n",
      "Iter:   125 | Cost: 0.4593946 | f1: 0.8687500 \n",
      "Iter:   126 | Cost: 0.4500890 | f1: 0.8625000 \n",
      "Iter:   127 | Cost: 0.4561604 | f1: 0.8544643 \n",
      "Iter:   128 | Cost: 0.4667460 | f1: 0.8455357 \n",
      "Iter:   129 | Cost: 0.4778516 | f1: 0.8366071 \n",
      "Iter:   130 | Cost: 0.4928361 | f1: 0.8258929 \n",
      "Iter:   131 | Cost: 0.5036327 | f1: 0.8151786 \n",
      "Iter:   132 | Cost: 0.5045655 | f1: 0.8160714 \n",
      "Iter:   133 | Cost: 0.4828644 | f1: 0.8357143 \n",
      "Iter:   134 | Cost: 0.4694704 | f1: 0.8508929 \n",
      "Iter:   135 | Cost: 0.4666193 | f1: 0.8562500 \n",
      "Iter:   136 | Cost: 0.4681521 | f1: 0.8616071 \n",
      "Iter:   137 | Cost: 0.4713746 | f1: 0.8633929 \n",
      "Iter:   138 | Cost: 0.4739546 | f1: 0.8633929 \n",
      "Iter:   139 | Cost: 0.4723095 | f1: 0.8633929 \n",
      "Iter:   140 | Cost: 0.4706612 | f1: 0.8633929 \n",
      "Iter:   141 | Cost: 0.4668554 | f1: 0.8633929 \n",
      "Iter:   142 | Cost: 0.4668823 | f1: 0.8642857 \n",
      "Iter:   143 | Cost: 0.4691483 | f1: 0.8651786 \n",
      "Iter:   144 | Cost: 0.4709643 | f1: 0.8651786 \n",
      "Iter:   145 | Cost: 0.4657452 | f1: 0.8651786 \n",
      "Iter:   146 | Cost: 0.4591219 | f1: 0.8660714 \n",
      "Iter:   147 | Cost: 0.4545672 | f1: 0.8651786 \n",
      "Iter:   148 | Cost: 0.4511851 | f1: 0.8642857 \n",
      "Iter:   149 | Cost: 0.4498200 | f1: 0.8633929 \n",
      "Iter:   150 | Cost: 0.4491078 | f1: 0.8616071 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 0 \n",
    "for it in range(150):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.accuracy_score(Y, predictions)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print('New best')\n",
    "    #prec = metrics.precision_score(Y, predictions, average='binary')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee2dceeb-5b76-4ec7-9ebb-efb9e562cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(label_test * 2 - np.ones(len(label_test)))\n",
    "Xte = np.array(normalize(sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03ecd991-b560-4868-9e42-1dcfe09d58ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    203\n",
       " 1.0     77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Yte).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4416ed73-4c7d-44e3-a539-9dba3191327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.5158124094433032, Accuracy: 84.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a2955a-d877-4885-ad84-5f31458a7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.83      0.99      0.90       203\n",
      "         1.0       0.92      0.45      0.61        77\n",
      "\n",
      "    accuracy                           0.84       280\n",
      "   macro avg       0.87      0.72      0.75       280\n",
      "weighted avg       0.85      0.84      0.82       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Yte, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcedeada-a82f-4e82-b738-6a862dc801c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 49.35%\n",
      "    Recall: 84.44%\n",
      "    f1: 62.3%\n",
      "    Accuracy: 83.57%\n",
      "    Balanced accuracy: 83.92%\n",
      "    Matthew corcorref: 55.81%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f1743f-35a8-4604-b4b7-e44b2936cc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 84.44%\n",
      "    Recall: 49.35%\n",
      "    f1: 62.3%\n",
      "    Accuracy: 83.57%\n",
      "    Balanced accuracy: 72.95%\n",
      "    Matthew corcorref: 55.81%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(Yte, predictions),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(Yte, predictions),2)}%\n",
    "    f1: {round(100*metrics.f1_score(Yte, predictions),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(Yte, predictions),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(Yte, predictions),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(Yte, predictions),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77acf9e4-6362-4daa-829c-a5c70138be5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.7837847 | f1: 0.3398329 \n",
      "Iter:     2 | Cost: 0.6468604 | f1: 0.0282686 \n",
      "Iter:     3 | Cost: 0.6890824 | f1: 0.0071685 \n",
      "Iter:     4 | Cost: 0.7594924 | f1: 0.0000000 \n",
      "Iter:     5 | Cost: 0.6646804 | f1: 0.0071685 \n",
      "Iter:     6 | Cost: 0.5017198 | f1: 0.3243243 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.4952593 | f1: 0.6603774 \n",
      "New best\n",
      "Iter:     8 | Cost: 0.5725122 | f1: 0.7429806 \n",
      "Iter:     9 | Cost: 0.5681912 | f1: 0.7363834 \n",
      "Iter:    10 | Cost: 0.5485545 | f1: 0.7187500 \n",
      "Iter:    11 | Cost: 0.4900122 | f1: 0.6603774 \n",
      "Iter:    12 | Cost: 0.4652018 | f1: 0.5909091 \n",
      "Iter:    13 | Cost: 0.4688597 | f1: 0.5506494 \n",
      "Iter:    14 | Cost: 0.4787903 | f1: 0.5000000 \n",
      "Iter:    15 | Cost: 0.4678385 | f1: 0.5506494 \n",
      "Iter:    16 | Cost: 0.4589827 | f1: 0.6000000 \n",
      "Iter:    17 | Cost: 0.4677693 | f1: 0.6394231 \n",
      "Iter:    18 | Cost: 0.5428852 | f1: 0.7174888 \n",
      "New best\n",
      "Iter:    19 | Cost: 0.5978691 | f1: 0.7432150 \n",
      "Iter:    20 | Cost: 0.5118448 | f1: 0.6972477 \n",
      "Iter:    21 | Cost: 0.4635610 | f1: 0.6361446 \n",
      "Iter:    22 | Cost: 0.4606720 | f1: 0.6191646 \n",
      "Iter:    23 | Cost: 0.4782999 | f1: 0.5567010 \n",
      "Iter:    24 | Cost: 0.5266254 | f1: 0.3884058 \n",
      "Iter:    25 | Cost: 0.5653777 | f1: 0.2732919 \n",
      "Iter:    26 | Cost: 0.5429935 | f1: 0.3598820 \n",
      "Iter:    27 | Cost: 0.5128014 | f1: 0.5392670 \n",
      "Iter:    28 | Cost: 0.5384396 | f1: 0.6191646 \n",
      "Iter:    29 | Cost: 0.5256937 | f1: 0.6191646 \n",
      "Iter:    30 | Cost: 0.4947139 | f1: 0.5985037 \n",
      "Iter:    31 | Cost: 0.4808184 | f1: 0.6019900 \n",
      "Iter:    32 | Cost: 0.4677909 | f1: 0.6054591 \n",
      "Iter:    33 | Cost: 0.4614950 | f1: 0.5964912 \n",
      "Iter:    34 | Cost: 0.4557625 | f1: 0.6034913 \n",
      "Iter:    35 | Cost: 0.4563323 | f1: 0.6191646 \n",
      "Iter:    36 | Cost: 0.4601802 | f1: 0.6191646 \n",
      "Iter:    37 | Cost: 0.4630399 | f1: 0.5822785 \n",
      "Iter:    38 | Cost: 0.4842852 | f1: 0.4640884 \n",
      "Iter:    39 | Cost: 0.5268831 | f1: 0.2892308 \n",
      "Iter:    40 | Cost: 0.5723665 | f1: 0.1770492 \n",
      "Iter:    41 | Cost: 0.5572926 | f1: 0.1889251 \n",
      "Iter:    42 | Cost: 0.4961650 | f1: 0.3742690 \n",
      "Iter:    43 | Cost: 0.4741732 | f1: 0.6050000 \n",
      "Iter:    44 | Cost: 0.4998158 | f1: 0.6508314 \n",
      "Iter:    45 | Cost: 0.5346433 | f1: 0.6790698 \n",
      "Iter:    46 | Cost: 0.6007194 | f1: 0.7352298 \n",
      "Iter:    47 | Cost: 0.6073860 | f1: 0.7375271 \n",
      "Iter:    48 | Cost: 0.5545404 | f1: 0.7045455 \n",
      "Iter:    49 | Cost: 0.4858584 | f1: 0.6459330 \n",
      "Iter:    50 | Cost: 0.4637089 | f1: 0.6000000 \n",
      "Iter:    51 | Cost: 0.4978882 | f1: 0.3837209 \n",
      "Iter:    52 | Cost: 0.5647191 | f1: 0.1650165 \n",
      "Iter:    53 | Cost: 0.5497713 | f1: 0.2006472 \n",
      "Iter:    54 | Cost: 0.4990166 | f1: 0.3742690 \n",
      "Iter:    55 | Cost: 0.4664894 | f1: 0.5801527 \n",
      "Iter:    56 | Cost: 0.4674795 | f1: 0.6326034 \n",
      "Iter:    57 | Cost: 0.4870365 | f1: 0.6426859 \n",
      "Iter:    58 | Cost: 0.5320128 | f1: 0.6867749 \n",
      "Iter:    59 | Cost: 0.5751284 | f1: 0.7191011 \n",
      "Iter:    60 | Cost: 0.6076309 | f1: 0.7221007 \n",
      "Iter:    61 | Cost: 0.5698925 | f1: 0.7045455 \n",
      "Iter:    62 | Cost: 0.5042329 | f1: 0.6426859 \n",
      "Iter:    63 | Cost: 0.4830271 | f1: 0.6277372 \n",
      "Iter:    64 | Cost: 0.4720395 | f1: 0.6191646 \n",
      "Iter:    65 | Cost: 0.4682669 | f1: 0.5964912 \n",
      "Iter:    66 | Cost: 0.4715766 | f1: 0.5641026 \n",
      "Iter:    67 | Cost: 0.4723817 | f1: 0.5604113 \n",
      "Iter:    68 | Cost: 0.4790099 | f1: 0.5315789 \n",
      "Iter:    69 | Cost: 0.4823183 | f1: 0.5238095 \n",
      "Iter:    70 | Cost: 0.4779696 | f1: 0.5315789 \n",
      "Iter:    71 | Cost: 0.4652603 | f1: 0.5714286 \n",
      "Iter:    72 | Cost: 0.4595664 | f1: 0.5964912 \n",
      "Iter:    73 | Cost: 0.4603472 | f1: 0.5964912 \n",
      "Iter:    74 | Cost: 0.4612672 | f1: 0.5858586 \n",
      "Iter:    75 | Cost: 0.4672356 | f1: 0.5604113 \n",
      "Iter:    76 | Cost: 0.4712468 | f1: 0.5454545 \n",
      "Iter:    77 | Cost: 0.4762507 | f1: 0.5224274 \n",
      "Iter:    78 | Cost: 0.4859630 | f1: 0.4932249 \n",
      "Iter:    79 | Cost: 0.5096103 | f1: 0.3930636 \n",
      "Iter:    80 | Cost: 0.5419941 | f1: 0.3151515 \n",
      "Iter:    81 | Cost: 0.5197413 | f1: 0.3742690 \n",
      "Iter:    82 | Cost: 0.4951048 | f1: 0.4683196 \n",
      "Iter:    83 | Cost: 0.4547181 | f1: 0.6000000 \n",
      "Iter:    84 | Cost: 0.4505733 | f1: 0.6259169 \n",
      "Iter:    85 | Cost: 0.4612034 | f1: 0.6426859 \n",
      "Iter:    86 | Cost: 0.4750720 | f1: 0.6619385 \n",
      "Iter:    87 | Cost: 0.5073619 | f1: 0.6956522 \n",
      "Iter:    88 | Cost: 0.5265325 | f1: 0.7104072 \n",
      "Iter:    89 | Cost: 0.5428679 | f1: 0.7158837 \n",
      "Iter:    90 | Cost: 0.5437660 | f1: 0.7174888 \n",
      "Iter:    91 | Cost: 0.5191465 | f1: 0.6972477 \n",
      "Iter:    92 | Cost: 0.4950231 | f1: 0.6650943 \n",
      "Iter:    93 | Cost: 0.4704319 | f1: 0.6394231 \n",
      "Iter:    94 | Cost: 0.4615854 | f1: 0.6000000 \n",
      "Iter:    95 | Cost: 0.4741036 | f1: 0.5378590 \n",
      "Iter:    96 | Cost: 0.4966351 | f1: 0.4683196 \n",
      "Iter:    97 | Cost: 0.5080563 | f1: 0.4068768 \n",
      "Iter:    98 | Cost: 0.4883892 | f1: 0.4932249 \n",
      "Iter:    99 | Cost: 0.4605901 | f1: 0.5750636 \n",
      "Iter:   100 | Cost: 0.4554881 | f1: 0.6310680 \n",
      "Iter:   101 | Cost: 0.4929125 | f1: 0.6744731 \n",
      "Iter:   102 | Cost: 0.5340475 | f1: 0.7117117 \n",
      "Iter:   103 | Cost: 0.5558670 | f1: 0.7168142 \n",
      "Iter:   104 | Cost: 0.5456335 | f1: 0.7187500 \n",
      "Iter:   105 | Cost: 0.5133039 | f1: 0.6986301 \n",
      "Iter:   106 | Cost: 0.4754152 | f1: 0.6491647 \n",
      "Iter:   107 | Cost: 0.4560800 | f1: 0.6326034 \n",
      "Iter:   108 | Cost: 0.4670210 | f1: 0.5618557 \n",
      "Iter:   109 | Cost: 0.4954133 | f1: 0.4114286 \n",
      "Iter:   110 | Cost: 0.4957940 | f1: 0.4114286 \n",
      "Iter:   111 | Cost: 0.5059460 | f1: 0.3884058 \n",
      "Iter:   112 | Cost: 0.4888223 | f1: 0.4598338 \n",
      "Iter:   113 | Cost: 0.4639961 | f1: 0.5618557 \n",
      "Iter:   114 | Cost: 0.4511099 | f1: 0.6069652 \n",
      "Iter:   115 | Cost: 0.4500010 | f1: 0.6359223 \n",
      "Iter:   116 | Cost: 0.4501586 | f1: 0.6425121 \n",
      "Iter:   117 | Cost: 0.4517200 | f1: 0.6409639 \n",
      "Iter:   118 | Cost: 0.4565008 | f1: 0.6394231 \n",
      "Iter:   119 | Cost: 0.4711157 | f1: 0.6587678 \n",
      "Iter:   120 | Cost: 0.4836813 | f1: 0.6744731 \n",
      "Iter:   121 | Cost: 0.4832558 | f1: 0.6713615 \n",
      "Iter:   122 | Cost: 0.4636122 | f1: 0.6426859 \n",
      "Iter:   123 | Cost: 0.4518421 | f1: 0.6259169 \n",
      "Iter:   124 | Cost: 0.4656609 | f1: 0.5604113 \n",
      "Iter:   125 | Cost: 0.5077792 | f1: 0.4068768 \n",
      "Iter:   126 | Cost: 0.5470613 | f1: 0.3151515 \n",
      "Iter:   127 | Cost: 0.5684529 | f1: 0.2515723 \n",
      "Iter:   128 | Cost: 0.5608777 | f1: 0.2732919 \n",
      "Iter:   129 | Cost: 0.5352983 | f1: 0.3550296 \n",
      "Iter:   130 | Cost: 0.4961732 | f1: 0.4640884 \n",
      "Iter:   131 | Cost: 0.4643887 | f1: 0.5750636 \n",
      "Iter:   132 | Cost: 0.4564765 | f1: 0.6191646 \n",
      "Iter:   133 | Cost: 0.4573732 | f1: 0.6409639 \n",
      "Iter:   134 | Cost: 0.4627470 | f1: 0.6394231 \n",
      "Iter:   135 | Cost: 0.4799682 | f1: 0.6635294 \n",
      "Iter:   136 | Cost: 0.5060052 | f1: 0.6912442 \n",
      "Iter:   137 | Cost: 0.5184732 | f1: 0.7045455 \n",
      "Iter:   138 | Cost: 0.4889716 | f1: 0.6759907 \n",
      "Iter:   139 | Cost: 0.4579587 | f1: 0.6326034 \n",
      "Iter:   140 | Cost: 0.4906174 | f1: 0.4114286 \n",
      "Iter:   141 | Cost: 0.5462527 | f1: 0.2515723 \n",
      "Iter:   142 | Cost: 0.5851851 | f1: 0.1830065 \n",
      "Iter:   143 | Cost: 0.5870822 | f1: 0.1830065 \n",
      "Iter:   144 | Cost: 0.5363265 | f1: 0.3048780 \n",
      "Iter:   145 | Cost: 0.4796764 | f1: 0.5159574 \n",
      "Iter:   146 | Cost: 0.4659474 | f1: 0.6157635 \n",
      "Iter:   147 | Cost: 0.4946432 | f1: 0.6459330 \n",
      "Iter:   148 | Cost: 0.5692777 | f1: 0.7104072 \n",
      "Iter:   149 | Cost: 0.6316338 | f1: 0.7276596 \n",
      "Iter:   150 | Cost: 0.5860196 | f1: 0.7187500 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 1 \n",
    "for it in range(150):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.f1_score(Y, predictions, average='binary', pos_label=1)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print('New best')\n",
    "    #prec = metrics.precision_score(Y, predictions, average='binary')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "615e6410-5955-469d-8ccd-32517ba8ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.5009974584580961, Accuracy: 84.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "694c231f-ce47-4bdb-be6a-eb1308ebc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.83      0.99      0.90       203\n",
      "         1.0       0.92      0.45      0.61        77\n",
      "\n",
      "    accuracy                           0.84       280\n",
      "   macro avg       0.87      0.72      0.75       280\n",
      "weighted avg       0.85      0.84      0.82       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Yte, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "660c69a6-87da-400e-99ba-739d49627088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 45.45%\n",
      "    Recall: 92.11%\n",
      "    f1: 60.87%\n",
      "    Accuracy: 83.93%\n",
      "    Balanced accuracy: 87.37%\n",
      "    Matthew corcorref: 57.33%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee63f17-2adf-48b6-9106-fb542ed641d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
