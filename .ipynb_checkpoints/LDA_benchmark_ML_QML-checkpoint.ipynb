{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41d3fa6-0ae0-490d-a02b-0dbf81799488",
   "metadata": {},
   "source": [
    "# Quantum benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6011e42-1fab-4f9f-ab99-f4f08607517e",
   "metadata": {},
   "source": [
    "## I - Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4f6b4-240b-4b7f-abe4-4e74b3b8cc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5492ce-4f08-4755-b4c2-efd698139101",
   "metadata": {},
   "source": [
    "## II - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90371200-0133-46ab-a205-d0f6b8858e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "#Import classical libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import functools\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "import logging\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9905d35-2c72-4bee-b088-9281e93aba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598c94c-fdcf-41cd-a4ea-e262932c7e0f",
   "metadata": {},
   "source": [
    "## III - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e683f3b5-6021-4eb7-bc53-539a5cd79bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out CSV\n",
    "\n",
    "df = pd.read_csv('UCI_Credit_Card.csv', sep=',')\n",
    "df = df.sample(1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf69c7f1-b10e-4b54-89ec-89dd5829ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "#EDA using Autoviz\n",
    "sweet_report = sv.analyze(df)\n",
    "\n",
    "#Saving results to HTML file\n",
    "sweet_report.show_html('sweet_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff48fa-d03b-435d-9343-67186c068b34",
   "metadata": {},
   "source": [
    "## IV - Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe1bb7-d7eb-412b-a291-bbeb654766f5",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7f6037b-3b1c-4a2c-8a9e-df1d432cafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df['default.payment.next.month']\n",
    "df.drop(['default.payment.next.month'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "249ef3a0-7be3-4234-8be6-630db2cd267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1251e3e-c8ed-4e57-a790-1fa8003f8c31",
   "metadata": {},
   "source": [
    "## Quantum Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a948c1c2-cb55-49b2-bb4c-c2d2fdca527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b921a949-e3bd-45b6-b0e0-a84f96788811",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = lda.fit_transform(X_train.iloc[:, :12], y_train)\n",
    "feature_2 = lda.fit_transform(X_train.iloc[:, 12:], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e05a6064-c96b-4446-8da3-d160af9592bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lda_1 = pd.DataFrame(feature_1)\n",
    "features_lda_2 = pd.DataFrame(feature_2)\n",
    "features_lda = features_lda_1.join(features_lda_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1de5099-55d4-4d2d-9ea4-eaf60c27b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = len(features_lda.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd626d5c-ff6a-443a-9700-10a93c24dc74",
   "metadata": {},
   "source": [
    "## Split train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afaf0912-bdbf-4460-ae4c-43016d1f5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "sample_train, sample_test, label_train, label_test = train_test_split(\n",
    "     features_lda, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "# Normalize\n",
    "\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Scale for better fit within the feature map\n",
    "\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Select a sample for a better control of the research and wall time\n",
    "\n",
    "train_size = 800#160\n",
    "sample_train = sample_train[:train_size]\n",
    "label_train = label_train[:train_size]\n",
    "\n",
    "test_size = 200 #40\n",
    "sample_test = sample_test[:test_size]\n",
    "label_test = label_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d815edbe-c5e7-42d6-9489-39ebb940cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters for hybrid model\n",
    "\n",
    "seed = 8500\n",
    "feature_dim = n_dim\n",
    "num_reps = 2\n",
    "num_shots =256 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bc9af-4a1c-453d-be99-d54b9e045628",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2ce7078-9255-4913-b6aa-7f05a0e077c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature_map\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=num_reps)\n",
    "\n",
    "# Define the backend\n",
    "backend = QuantumInstance(\n",
    "    BasicAer.get_backend(\"qasm_simulator\"), shots=num_shots, seed_simulator=seed, seed_transpiler=seed\n",
    ")\n",
    "\n",
    "# Define the kernel\n",
    "\n",
    "kernel = QuantumKernel(feature_map=feature_map, quantum_instance=backend)\n",
    "\n",
    "# Model run\n",
    "svc = SVC(kernel=kernel.evaluate)\n",
    "#svc.fit(sample_train, label_train)\n",
    "#score = svc.score(sample_test, label_test)\n",
    "\n",
    "#print(f\"Callable kernel classification test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8fd86d8-bec9-42ac-8543-c69c973a7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_predict = svc.predict(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee71fc2a-46dc-46d1-8f51-8e3df5723407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(label_test,result_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "faba4365-8252-470c-91b1-cfa74b2cacc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from tqdm import tqdm\n",
    "def evaluate_ml_model(_models, X, y, n_fold=10, metric='precision'):\n",
    "    ''' Function to evaluate a ML and QML model with a list of metrics\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    results = pd.DataFrame()\n",
    "    kfold = KFold(n_splits=n_fold)\n",
    "    columns = []\n",
    "    for name, model in tqdm(_models):\n",
    "        # -------------------\n",
    "        # Variables initialization \n",
    "        _df = pd.DataFrame()\n",
    "        names = []\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        # -------------------\n",
    "        # k-fold Cross validation\n",
    "        cv_results = cross_validate(model, X, y, cv=kfold, scoring=metric)\n",
    "        \n",
    "        # -------------------\n",
    "        # Compute the mean and standard deviation \n",
    "        for _name, _array in cv_results.items():\n",
    "            names.append(_name)\n",
    "            means.append(round(100*_array.mean(), 2))\n",
    "            stds.append(round(100*_array.std(), 2))\n",
    "        # -------------------\n",
    "        # Save the results in a dataframe \n",
    "        _df =  pd.DataFrame([means, stds], columns=names)\n",
    "        columns.extend([name+' mean (%)', name+' std (%)'])\n",
    "        #results = results.join(_df, on=_df.index)\n",
    "        results = results.append(_df)\n",
    "    results.index = columns\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d26b93e-ba48-47f3-84af-fc8b09d9ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('qsvc', svc))\n",
    "_metrics = ['precision', 'recall', 'f1', 'accuracy',  'matthews_corrcoef','balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec24e291-a808-4c2c-857f-98ccc0e5e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [1:00:03<00:00, 600.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fit_time  score_time  test_precision  test_recall  test_f1  \\\n",
      "LR mean (%)        0.38        0.23           64.75        12.36    19.89   \n",
      "LR std (%)         0.58        0.21           37.02         9.46    14.14   \n",
      "KNN mean (%)       0.06        0.31           57.06        33.36    40.71   \n",
      "KNN std (%)        0.05        0.22           20.44        12.55    12.24   \n",
      "CART mean (%)      0.14        0.14           34.83        34.12    33.93   \n",
      "CART std (%)       0.08        0.02            9.49        11.25     9.39   \n",
      "NB mean (%)        0.04        0.12           62.58        39.13    47.41   \n",
      "NB std (%)         0.03        0.01           15.57         9.38    10.23   \n",
      "SVM mean (%)       0.72        0.24           66.64        22.86    33.20   \n",
      "SVM std (%)        0.95        0.06           11.82         9.57    11.84   \n",
      "qsvc mean (%)  30271.75     5762.85           67.02        33.44    43.96   \n",
      "qsvc std (%)     782.70      152.63           13.31        10.08    10.97   \n",
      "\n",
      "               test_accuracy  test_matthews_corrcoef  test_balanced_accuracy  \n",
      "LR mean (%)            80.62                   22.66                   55.61  \n",
      "LR std (%)              3.84                   14.89                    4.39  \n",
      "KNN mean (%)           80.12                   32.17                   62.99  \n",
      "KNN std (%)             3.51                   14.40                    6.60  \n",
      "CART mean (%)          72.75                   17.25                   58.60  \n",
      "CART std (%)            3.20                   10.27                    5.34  \n",
      "NB mean (%)            82.00                   39.19                   66.25  \n",
      "NB std (%)              3.12                   11.71                    5.07  \n",
      "SVM mean (%)           81.50                   30.90                   60.01  \n",
      "SVM std (%)             2.84                   10.38                    4.51  \n",
      "qsvc mean (%)          82.62                   38.51                   64.60  \n",
      "qsvc std (%)            2.40                   10.97                    5.08  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_matthews_corrcoef</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR mean (%)</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>64.75</td>\n",
       "      <td>12.36</td>\n",
       "      <td>19.89</td>\n",
       "      <td>80.62</td>\n",
       "      <td>22.66</td>\n",
       "      <td>55.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR std (%)</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.21</td>\n",
       "      <td>37.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>14.14</td>\n",
       "      <td>3.84</td>\n",
       "      <td>14.89</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN mean (%)</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.31</td>\n",
       "      <td>57.06</td>\n",
       "      <td>33.36</td>\n",
       "      <td>40.71</td>\n",
       "      <td>80.12</td>\n",
       "      <td>32.17</td>\n",
       "      <td>62.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN std (%)</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.44</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.24</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.40</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART mean (%)</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>34.83</td>\n",
       "      <td>34.12</td>\n",
       "      <td>33.93</td>\n",
       "      <td>72.75</td>\n",
       "      <td>17.25</td>\n",
       "      <td>58.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART std (%)</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9.49</td>\n",
       "      <td>11.25</td>\n",
       "      <td>9.39</td>\n",
       "      <td>3.20</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB mean (%)</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>62.58</td>\n",
       "      <td>39.13</td>\n",
       "      <td>47.41</td>\n",
       "      <td>82.00</td>\n",
       "      <td>39.19</td>\n",
       "      <td>66.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB std (%)</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15.57</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.23</td>\n",
       "      <td>3.12</td>\n",
       "      <td>11.71</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM mean (%)</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.24</td>\n",
       "      <td>66.64</td>\n",
       "      <td>22.86</td>\n",
       "      <td>33.20</td>\n",
       "      <td>81.50</td>\n",
       "      <td>30.90</td>\n",
       "      <td>60.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM std (%)</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.06</td>\n",
       "      <td>11.82</td>\n",
       "      <td>9.57</td>\n",
       "      <td>11.84</td>\n",
       "      <td>2.84</td>\n",
       "      <td>10.38</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsvc mean (%)</th>\n",
       "      <td>30271.75</td>\n",
       "      <td>5762.85</td>\n",
       "      <td>67.02</td>\n",
       "      <td>33.44</td>\n",
       "      <td>43.96</td>\n",
       "      <td>82.62</td>\n",
       "      <td>38.51</td>\n",
       "      <td>64.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsvc std (%)</th>\n",
       "      <td>782.70</td>\n",
       "      <td>152.63</td>\n",
       "      <td>13.31</td>\n",
       "      <td>10.08</td>\n",
       "      <td>10.97</td>\n",
       "      <td>2.40</td>\n",
       "      <td>10.97</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fit_time  score_time  test_precision  test_recall  test_f1  \\\n",
       "LR mean (%)        0.38        0.23           64.75        12.36    19.89   \n",
       "LR std (%)         0.58        0.21           37.02         9.46    14.14   \n",
       "KNN mean (%)       0.06        0.31           57.06        33.36    40.71   \n",
       "KNN std (%)        0.05        0.22           20.44        12.55    12.24   \n",
       "CART mean (%)      0.14        0.14           34.83        34.12    33.93   \n",
       "CART std (%)       0.08        0.02            9.49        11.25     9.39   \n",
       "NB mean (%)        0.04        0.12           62.58        39.13    47.41   \n",
       "NB std (%)         0.03        0.01           15.57         9.38    10.23   \n",
       "SVM mean (%)       0.72        0.24           66.64        22.86    33.20   \n",
       "SVM std (%)        0.95        0.06           11.82         9.57    11.84   \n",
       "qsvc mean (%)  30271.75     5762.85           67.02        33.44    43.96   \n",
       "qsvc std (%)     782.70      152.63           13.31        10.08    10.97   \n",
       "\n",
       "               test_accuracy  test_matthews_corrcoef  test_balanced_accuracy  \n",
       "LR mean (%)            80.62                   22.66                   55.61  \n",
       "LR std (%)              3.84                   14.89                    4.39  \n",
       "KNN mean (%)           80.12                   32.17                   62.99  \n",
       "KNN std (%)             3.51                   14.40                    6.60  \n",
       "CART mean (%)          72.75                   17.25                   58.60  \n",
       "CART std (%)            3.20                   10.27                    5.34  \n",
       "NB mean (%)            82.00                   39.19                   66.25  \n",
       "NB std (%)              3.12                   11.71                    5.07  \n",
       "SVM mean (%)           81.50                   30.90                   60.01  \n",
       "SVM std (%)             2.84                   10.38                    4.51  \n",
       "qsvc mean (%)          82.62                   38.51                   64.60  \n",
       "qsvc std (%)            2.40                   10.97                    5.08  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results = evaluate_ml_model(models, sample_train, label_train, n_fold=10, metric=_metrics)\n",
    "df_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4e79c7c-d2c5-4cfd-b731-4bf2de012796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR & 64.75 (37.02) & 12.36 (9.46) &  19.89 (14.14) & 22.66 (14.89) & & 55.61 (4.39) \\\n",
      "KNN & 57.06 (20.44) & 33.36 (12.55) &  40.71 (12.24) & 32.17 (14.4) & & 62.99 (6.6) \\\n",
      "CART & 34.83 (9.49) & 34.12 (11.25) &  33.93 (9.39) & 17.25 (10.27) & & 58.6 (5.34) \\\n",
      "NB & 62.58 (15.57) & 39.13 (9.38) &  47.41 (10.23) & 39.19 (11.71) & & 66.25 (5.07) \\\n",
      "SVM & 66.64 (11.82) & 22.86 (9.57) &  33.2 (11.84) & 30.9 (10.38) & & 60.01 (4.51) \\\n",
      "qsvc & 67.02 (13.31) & 33.44 (10.08) &  43.96 (10.97) & 38.51 (10.97) & & 64.6 (5.08) \\\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in range(int(len(df_results.index)/2)):\n",
    "\n",
    "    print(f'{df_results.iloc[j].name.split()[0]} & {df_results.iloc[j][2]} ({df_results.iloc[j+1][2]}) & {df_results.iloc[j][3]} ({df_results.iloc[j+1][3]}) &  {df_results.iloc[j][4]} ({df_results.iloc[j+1][4]}) & {df_results.iloc[j][6]} ({df_results.iloc[j+1][6]}) & & {df_results.iloc[j][7]} ({df_results.iloc[j+1][7]}) \\\\')\n",
    "    \n",
    "    j+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca5f98e3-d65c-479d-9268-8396091ec9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_matthews_corrcoef</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR mean (%)</th>\n",
       "      <td>64.75</td>\n",
       "      <td>12.36</td>\n",
       "      <td>19.89</td>\n",
       "      <td>22.66</td>\n",
       "      <td>55.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR std (%)</th>\n",
       "      <td>37.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>14.14</td>\n",
       "      <td>14.89</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN mean (%)</th>\n",
       "      <td>57.06</td>\n",
       "      <td>33.36</td>\n",
       "      <td>40.71</td>\n",
       "      <td>32.17</td>\n",
       "      <td>62.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN std (%)</th>\n",
       "      <td>20.44</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.24</td>\n",
       "      <td>14.40</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART mean (%)</th>\n",
       "      <td>34.83</td>\n",
       "      <td>34.12</td>\n",
       "      <td>33.93</td>\n",
       "      <td>17.25</td>\n",
       "      <td>58.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART std (%)</th>\n",
       "      <td>9.49</td>\n",
       "      <td>11.25</td>\n",
       "      <td>9.39</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB mean (%)</th>\n",
       "      <td>62.58</td>\n",
       "      <td>39.13</td>\n",
       "      <td>47.41</td>\n",
       "      <td>39.19</td>\n",
       "      <td>66.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB std (%)</th>\n",
       "      <td>15.57</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.23</td>\n",
       "      <td>11.71</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM mean (%)</th>\n",
       "      <td>66.64</td>\n",
       "      <td>22.86</td>\n",
       "      <td>33.20</td>\n",
       "      <td>30.90</td>\n",
       "      <td>60.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM std (%)</th>\n",
       "      <td>11.82</td>\n",
       "      <td>9.57</td>\n",
       "      <td>11.84</td>\n",
       "      <td>10.38</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsvc mean (%)</th>\n",
       "      <td>67.02</td>\n",
       "      <td>33.44</td>\n",
       "      <td>43.96</td>\n",
       "      <td>38.51</td>\n",
       "      <td>64.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsvc std (%)</th>\n",
       "      <td>13.31</td>\n",
       "      <td>10.08</td>\n",
       "      <td>10.97</td>\n",
       "      <td>10.97</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test_precision  test_recall  test_f1  test_matthews_corrcoef  \\\n",
       "LR mean (%)             64.75        12.36    19.89                   22.66   \n",
       "LR std (%)              37.02         9.46    14.14                   14.89   \n",
       "KNN mean (%)            57.06        33.36    40.71                   32.17   \n",
       "KNN std (%)             20.44        12.55    12.24                   14.40   \n",
       "CART mean (%)           34.83        34.12    33.93                   17.25   \n",
       "CART std (%)             9.49        11.25     9.39                   10.27   \n",
       "NB mean (%)             62.58        39.13    47.41                   39.19   \n",
       "NB std (%)              15.57         9.38    10.23                   11.71   \n",
       "SVM mean (%)            66.64        22.86    33.20                   30.90   \n",
       "SVM std (%)             11.82         9.57    11.84                   10.38   \n",
       "qsvc mean (%)           67.02        33.44    43.96                   38.51   \n",
       "qsvc std (%)            13.31        10.08    10.97                   10.97   \n",
       "\n",
       "               test_balanced_accuracy  \n",
       "LR mean (%)                     55.61  \n",
       "LR std (%)                       4.39  \n",
       "KNN mean (%)                    62.99  \n",
       "KNN std (%)                      6.60  \n",
       "CART mean (%)                   58.60  \n",
       "CART std (%)                     5.34  \n",
       "NB mean (%)                     66.25  \n",
       "NB std (%)                       5.07  \n",
       "SVM mean (%)                    60.01  \n",
       "SVM std (%)                      4.51  \n",
       "qsvc mean (%)                   64.60  \n",
       "qsvc std (%)                     5.08  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[['test_precision', 'test_recall', 'test_f1', 'test_matthews_corrcoef', 'test_balanced_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70b837-4e39-4b65-83ca-8e82fc83efa1",
   "metadata": {},
   "source": [
    "## Pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff1d5656-f2f2-4d96-b210-a75a161cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07ec49f5-c401-4c36-aae3-57aad3eaa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = n_dim\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffcf8fdb-37a0-4b64-b73c-76be553995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "#print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49568595-37ec-4749-a230-dc4c6dae2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.21522869, requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, sample_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4febb380-0955-4f05-a872-326cc4e3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c16a1f84-63e5-4fbb-a647-cba6db4c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07412a53-c93b-4c73-bd0b-e7e144454435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bf0b58e-38f3-4c45-a4d2-3d69af787ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21ff4aa6-c15b-4a59-a718-67d8da2402dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(-0.4839139, requires_grad=True), tensor(0.46245099, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.40709255, requires_grad=True), tensor(0.46730758, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.40615338, requires_grad=True), tensor(0.46321553, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.49246467, requires_grad=True), tensor(0.46501907, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.48159592, requires_grad=True), tensor(0.45046177, requires_grad=True)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(label_train * 2 - np.ones(len(label_train)),requires_grad=True)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(sample_train, requires_grad=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "074f578a-1984-4814-9070-7b20063c8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a78e0005-464d-46c0-86f4-946291d7586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d31d6a7-74f4-4e63-b1cb-b92bfb610a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.6933689 | f1: 0.0756757 \n",
      "Iter:     2 | Cost: 0.6591815 | f1: 0.0231214 \n",
      "Iter:     3 | Cost: 0.6841310 | f1: 0.0116959 \n",
      "Iter:     4 | Cost: 0.7687057 | f1: 0.0116959 \n",
      "Iter:     5 | Cost: 0.6619744 | f1: 0.0346821 \n",
      "Iter:     6 | Cost: 0.6196701 | f1: 0.0459770 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.6331537 | f1: 0.0786517 \n",
      "Iter:     8 | Cost: 0.6115958 | f1: 0.0571429 \n",
      "Iter:     9 | Cost: 0.6097674 | f1: 0.0346821 \n",
      "Iter:    10 | Cost: 0.6099742 | f1: 0.0346821 \n",
      "Iter:    11 | Cost: 0.6005755 | f1: 0.0459770 \n",
      "Iter:    12 | Cost: 0.5994139 | f1: 0.0459770 \n",
      "Iter:    13 | Cost: 0.5939629 | f1: 0.0459770 \n",
      "New best\n",
      "Iter:    14 | Cost: 0.5960130 | f1: 0.0786517 \n",
      "Iter:    15 | Cost: 0.5970916 | f1: 0.0786517 \n",
      "New best\n",
      "Iter:    16 | Cost: 0.5956066 | f1: 0.0786517 \n",
      "Iter:    17 | Cost: 0.5962448 | f1: 0.0786517 \n",
      "New best\n",
      "Iter:    18 | Cost: 0.6057498 | f1: 0.0983607 \n",
      "Iter:    19 | Cost: 0.6088319 | f1: 0.0978261 \n",
      "New best\n",
      "Iter:    20 | Cost: 0.6043323 | f1: 0.0989011 \n",
      "Iter:    21 | Cost: 0.5947169 | f1: 0.0786517 \n",
      "Iter:    22 | Cost: 0.5895015 | f1: 0.0571429 \n",
      "Iter:    23 | Cost: 0.5965747 | f1: 0.0459770 \n",
      "Iter:    24 | Cost: 0.6223131 | f1: 0.0346821 \n",
      "Iter:    25 | Cost: 0.6307255 | f1: 0.0346821 \n",
      "Iter:    26 | Cost: 0.6273200 | f1: 0.0346821 \n",
      "Iter:    27 | Cost: 0.6198470 | f1: 0.0346821 \n",
      "Iter:    28 | Cost: 0.6010583 | f1: 0.0459770 \n",
      "Iter:    29 | Cost: 0.5890037 | f1: 0.0459770 \n",
      "Iter:    30 | Cost: 0.5910716 | f1: 0.0571429 \n",
      "Iter:    31 | Cost: 0.5934060 | f1: 0.0677966 \n",
      "New best\n",
      "Iter:    32 | Cost: 0.6244421 | f1: 0.1283422 \n",
      "New best\n",
      "Iter:    33 | Cost: 0.6657860 | f1: 0.3090909 \n",
      "New best\n",
      "Iter:    34 | Cost: 0.6902641 | f1: 0.4262295 \n",
      "Iter:    35 | Cost: 0.6464744 | f1: 0.2938389 \n",
      "Iter:    36 | Cost: 0.5970555 | f1: 0.0782123 \n",
      "Iter:    37 | Cost: 0.5924957 | f1: 0.0459770 \n",
      "Iter:    38 | Cost: 0.6385776 | f1: 0.0346821 \n",
      "Iter:    39 | Cost: 0.6828138 | f1: 0.0346821 \n",
      "Iter:    40 | Cost: 0.7016294 | f1: 0.0346821 \n",
      "Iter:    41 | Cost: 0.6832764 | f1: 0.0346821 \n",
      "Iter:    42 | Cost: 0.6278334 | f1: 0.0346821 \n",
      "Iter:    43 | Cost: 0.6084193 | f1: 0.0571429 \n",
      "Iter:    44 | Cost: 0.6428968 | f1: 0.0983607 \n",
      "Iter:    45 | Cost: 0.6842649 | f1: 0.2549020 \n",
      "Iter:    46 | Cost: 0.7346338 | f1: 0.4180328 \n",
      "Iter:    47 | Cost: 0.7087891 | f1: 0.3257919 \n",
      "Iter:    48 | Cost: 0.6437082 | f1: 0.0989011 \n",
      "Iter:    49 | Cost: 0.6063306 | f1: 0.0459770 \n",
      "Iter:    50 | Cost: 0.6359701 | f1: 0.0346821 \n",
      "Iter:    51 | Cost: 0.6971331 | f1: 0.0346821 \n",
      "Iter:    52 | Cost: 0.7220349 | f1: 0.0346821 \n",
      "Iter:    53 | Cost: 0.7025242 | f1: 0.0346821 \n",
      "Iter:    54 | Cost: 0.6479377 | f1: 0.0346821 \n",
      "Iter:    55 | Cost: 0.6093886 | f1: 0.0459770 \n",
      "Iter:    56 | Cost: 0.5958154 | f1: 0.0459770 \n",
      "Iter:    57 | Cost: 0.6079591 | f1: 0.0888889 \n",
      "Iter:    58 | Cost: 0.6658478 | f1: 0.3423423 \n",
      "New best\n",
      "Iter:    59 | Cost: 0.7105337 | f1: 0.4674330 \n",
      "New best\n",
      "Iter:    60 | Cost: 0.7355309 | f1: 0.5000000 \n",
      "Iter:    61 | Cost: 0.6737846 | f1: 0.3862661 \n",
      "Iter:    62 | Cost: 0.6369911 | f1: 0.2731707 \n",
      "Iter:    63 | Cost: 0.6098212 | f1: 0.1081081 \n",
      "Iter:    64 | Cost: 0.6062428 | f1: 0.0983607 \n",
      "Iter:    65 | Cost: 0.5963366 | f1: 0.0786517 \n",
      "Iter:    66 | Cost: 0.5929126 | f1: 0.0786517 \n",
      "Iter:    67 | Cost: 0.5921750 | f1: 0.0677966 \n",
      "Iter:    68 | Cost: 0.5941708 | f1: 0.0571429 \n",
      "Iter:    69 | Cost: 0.5931474 | f1: 0.0571429 \n",
      "Iter:    70 | Cost: 0.5936614 | f1: 0.0571429 \n",
      "Iter:    71 | Cost: 0.5933721 | f1: 0.0571429 \n",
      "Iter:    72 | Cost: 0.5999045 | f1: 0.0459770 \n",
      "Iter:    73 | Cost: 0.6109828 | f1: 0.0459770 \n",
      "Iter:    74 | Cost: 0.6180195 | f1: 0.0459770 \n",
      "Iter:    75 | Cost: 0.6268691 | f1: 0.0346821 \n",
      "Iter:    76 | Cost: 0.6545139 | f1: 0.0346821 \n",
      "Iter:    77 | Cost: 0.7005276 | f1: 0.0346821 \n",
      "Iter:    78 | Cost: 0.7386486 | f1: 0.0346821 \n",
      "Iter:    79 | Cost: 0.7317851 | f1: 0.0346821 \n",
      "Iter:    80 | Cost: 0.7265894 | f1: 0.0346821 \n",
      "Iter:    81 | Cost: 0.6528041 | f1: 0.0346821 \n",
      "Iter:    82 | Cost: 0.5902246 | f1: 0.0459770 \n",
      "Iter:    83 | Cost: 0.6115194 | f1: 0.1081081 \n",
      "Iter:    84 | Cost: 0.6559361 | f1: 0.3196347 \n",
      "Iter:    85 | Cost: 0.6212204 | f1: 0.1770833 \n",
      "Iter:    86 | Cost: 0.5885403 | f1: 0.0459770 \n",
      "Iter:    87 | Cost: 0.6330833 | f1: 0.0346821 \n",
      "Iter:    88 | Cost: 0.6647084 | f1: 0.0346821 \n",
      "Iter:    89 | Cost: 0.6285510 | f1: 0.0346821 \n",
      "Iter:    90 | Cost: 0.5976727 | f1: 0.0459770 \n",
      "Iter:    91 | Cost: 0.5979156 | f1: 0.0786517 \n",
      "Iter:    92 | Cost: 0.6100484 | f1: 0.0994475 \n",
      "Iter:    93 | Cost: 0.6088752 | f1: 0.0994475 \n",
      "Iter:    94 | Cost: 0.6125132 | f1: 0.0989011 \n",
      "Iter:    95 | Cost: 0.6067747 | f1: 0.0782123 \n",
      "Iter:    96 | Cost: 0.6066509 | f1: 0.0786517 \n",
      "Iter:    97 | Cost: 0.5994196 | f1: 0.0786517 \n",
      "Iter:    98 | Cost: 0.5948558 | f1: 0.0571429 \n",
      "Iter:    99 | Cost: 0.6054194 | f1: 0.0459770 \n",
      "Iter:   100 | Cost: 0.6349128 | f1: 0.0346821 \n",
      "Iter:   101 | Cost: 0.6712918 | f1: 0.0346821 \n",
      "Iter:   102 | Cost: 0.7147502 | f1: 0.0346821 \n",
      "Iter:   103 | Cost: 0.7028663 | f1: 0.0346821 \n",
      "Iter:   104 | Cost: 0.6475256 | f1: 0.0346821 \n",
      "Iter:   105 | Cost: 0.5943833 | f1: 0.0571429 \n",
      "Iter:   106 | Cost: 0.6068024 | f1: 0.0786517 \n",
      "Iter:   107 | Cost: 0.6050065 | f1: 0.0786517 \n",
      "Iter:   108 | Cost: 0.5966338 | f1: 0.0677966 \n",
      "Iter:   109 | Cost: 0.6256231 | f1: 0.1770833 \n",
      "Iter:   110 | Cost: 0.6253622 | f1: 0.1761658 \n",
      "Iter:   111 | Cost: 0.6221444 | f1: 0.1761658 \n",
      "Iter:   112 | Cost: 0.6079228 | f1: 0.0978261 \n",
      "Iter:   113 | Cost: 0.5902850 | f1: 0.0571429 \n",
      "Iter:   114 | Cost: 0.5923757 | f1: 0.0571429 \n",
      "Iter:   115 | Cost: 0.5902063 | f1: 0.0571429 \n",
      "Iter:   116 | Cost: 0.5936915 | f1: 0.0459770 \n",
      "Iter:   117 | Cost: 0.5933532 | f1: 0.0459770 \n",
      "Iter:   118 | Cost: 0.5964835 | f1: 0.0459770 \n",
      "Iter:   119 | Cost: 0.6090203 | f1: 0.0459770 \n",
      "Iter:   120 | Cost: 0.6269613 | f1: 0.0346821 \n",
      "Iter:   121 | Cost: 0.6364075 | f1: 0.0346821 \n",
      "Iter:   122 | Cost: 0.6252685 | f1: 0.0346821 \n",
      "Iter:   123 | Cost: 0.6101026 | f1: 0.0459770 \n",
      "Iter:   124 | Cost: 0.6065712 | f1: 0.0459770 \n",
      "Iter:   125 | Cost: 0.6036303 | f1: 0.0459770 \n",
      "Iter:   126 | Cost: 0.5986892 | f1: 0.0459770 \n",
      "Iter:   127 | Cost: 0.5934482 | f1: 0.0459770 \n",
      "Iter:   128 | Cost: 0.5901594 | f1: 0.0571429 \n",
      "Iter:   129 | Cost: 0.5885035 | f1: 0.0571429 \n",
      "Iter:   130 | Cost: 0.5925181 | f1: 0.0786517 \n",
      "Iter:   131 | Cost: 0.6068388 | f1: 0.1182796 \n",
      "Iter:   132 | Cost: 0.6288519 | f1: 0.2815534 \n",
      "Iter:   133 | Cost: 0.6389645 | f1: 0.3041475 \n",
      "Iter:   134 | Cost: 0.6292523 | f1: 0.2815534 \n",
      "Iter:   135 | Cost: 0.6064505 | f1: 0.1283422 \n",
      "Iter:   136 | Cost: 0.5921416 | f1: 0.0786517 \n",
      "Iter:   137 | Cost: 0.5899882 | f1: 0.0571429 \n",
      "Iter:   138 | Cost: 0.6002352 | f1: 0.0459770 \n",
      "Iter:   139 | Cost: 0.6048340 | f1: 0.0459770 \n",
      "Iter:   140 | Cost: 0.6137957 | f1: 0.0459770 \n",
      "Iter:   141 | Cost: 0.6193547 | f1: 0.0346821 \n",
      "Iter:   142 | Cost: 0.6131626 | f1: 0.0459770 \n",
      "Iter:   143 | Cost: 0.6039011 | f1: 0.0459770 \n",
      "Iter:   144 | Cost: 0.6028891 | f1: 0.0459770 \n",
      "Iter:   145 | Cost: 0.6068262 | f1: 0.0459770 \n",
      "Iter:   146 | Cost: 0.6004299 | f1: 0.0459770 \n",
      "Iter:   147 | Cost: 0.5921527 | f1: 0.0459770 \n",
      "Iter:   148 | Cost: 0.5971945 | f1: 0.0677966 \n",
      "Iter:   149 | Cost: 0.6537044 | f1: 0.1761658 \n",
      "New best\n",
      "Iter:   150 | Cost: 0.8101237 | f1: 0.5211726 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 0 \n",
    "for it in range(150):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.f1_score(Y, predictions, average='binary', pos_label=1)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print('New best')\n",
    "    #prec = metrics.precision_score(Y, predictions, average='binary')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee2dceeb-5b76-4ec7-9ebb-efb9e562cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(label_test * 2 - np.ones(len(label_test)))\n",
    "Xte = np.array(normalize(sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4416ed73-4c7d-44e3-a539-9dba3191327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.7001960421871015, Accuracy: 83.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c50c097-603d-439b-84a9-cd649bcbeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.84      0.90       176\n",
      "         1.0       0.39      0.75      0.51        24\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.68      0.80      0.71       200\n",
      "weighted avg       0.89      0.83      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4a2955a-d877-4885-ad84-5f31458a7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.88      0.88      0.88       160\n",
      "         1.0       0.53      0.53      0.53        40\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcedeada-a82f-4e82-b738-6a862dc801c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 39.13%\n",
      "    Recall: 75.0%\n",
      "    f1: 51.43%\n",
      "    Accuracy: 83.0%\n",
      "    Balanced accuracy: 79.55%\n",
      "    Matthew corcorref: 45.63%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5308be-6630-4637-a387-b4f796aeb98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acf9e4-6362-4daa-829c-a5c70138be5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
