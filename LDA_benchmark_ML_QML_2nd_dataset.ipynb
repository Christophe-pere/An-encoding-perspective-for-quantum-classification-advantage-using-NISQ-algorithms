{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41d3fa6-0ae0-490d-a02b-0dbf81799488",
   "metadata": {},
   "source": [
    "# Quantum benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6011e42-1fab-4f9f-ab99-f4f08607517e",
   "metadata": {},
   "source": [
    "## I - Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4f6b4-240b-4b7f-abe4-4e74b3b8cc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5492ce-4f08-4755-b4c2-efd698139101",
   "metadata": {},
   "source": [
    "## II - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90371200-0133-46ab-a205-d0f6b8858e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "#Import classical libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import functools\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "import logging\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4552ad2-d5ac-4904-8e45-eafa355e4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598c94c-fdcf-41cd-a4ea-e262932c7e0f",
   "metadata": {},
   "source": [
    "## III - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e683f3b5-6021-4eb7-bc53-539a5cd79bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out CSV\n",
    "\n",
    "df = pd.read_csv('santander_transaction.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10255383-ae13-42c1-8d19-b5cf9eca4d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 201)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf69c7f1-b10e-4b54-89ec-89dd5829ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "#EDA using Autoviz\n",
    "sweet_report = sv.analyze(df)\n",
    "\n",
    "#Saving results to HTML file\n",
    "sweet_report.show_html('sweet_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff48fa-d03b-435d-9343-67186c068b34",
   "metadata": {},
   "source": [
    "## IV - Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe1bb7-d7eb-412b-a291-bbeb654766f5",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f6037b-3b1c-4a2c-8a9e-df1d432cafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labels = df['target']\n",
    "df.drop(['target'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249ef3a0-7be3-4234-8be6-630db2cd267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1251e3e-c8ed-4e57-a790-1fa8003f8c31",
   "metadata": {},
   "source": [
    "## Quantum Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b4f425-f8b1-40b4-8c3f-4502a9a01a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a948c1c2-cb55-49b2-bb4c-c2d2fdca527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_1 = LDA(n_components=1)\n",
    "lda_2 = LDA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b921a949-e3bd-45b6-b0e0-a84f96788811",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_1.fit(X_train.iloc[:, :100], y_train)\n",
    "feature_1 = lda_1.transform(X_train.iloc[:, :100])\n",
    "lda_2.fit(X_train.iloc[:, 100:], y_train)\n",
    "feature_2 = lda_2.transform(X_train.iloc[:, 100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333f641b-b9b7-498d-9b52-26f2fac93938",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = lda_1.transform(X_test.iloc[:, :100])\n",
    "test_2 = lda_2.transform(X_test.iloc[:, 100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e05a6064-c96b-4446-8da3-d160af9592bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_lda_1 = pd.DataFrame(feature_1)\n",
    "features_lda_2 = pd.DataFrame(feature_2)\n",
    "features_lda = features_lda_1.join(features_lda_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b32050d4-fbc7-4ab4-ba40-f3a56ae6dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lda_1 =pd.DataFrame(test_1)\n",
    "test_lda_2 =pd.DataFrame(test_2)\n",
    "test_lda = test_lda_1.join(test_lda_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1de5099-55d4-4d2d-9ea4-eaf60c27b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = len(features_lda.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd626d5c-ff6a-443a-9700-10a93c24dc74",
   "metadata": {},
   "source": [
    "## Split train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afaf0912-bdbf-4460-ae4c-43016d1f5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "#sample_train, sample_test, label_train, label_test = train_test_split(\n",
    "#     features_lda, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "sample_train = features_lda.to_numpy()\n",
    "sample_test = test_lda.to_numpy()\n",
    "label_train = y_train\n",
    "label_test = y_test\n",
    "# Normalize\n",
    "\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Scale for better fit within the feature map\n",
    "\n",
    "#samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(sample_train)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Select a sample for a better control of the research and wall time\n",
    "\n",
    "\n",
    "#test_size = 200 #40\n",
    "#sample_test = sample_test[:test_size]\n",
    "#label_test = label_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d815edbe-c5e7-42d6-9489-39ebb940cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters for hybrid model\n",
    "\n",
    "seed = 8500\n",
    "feature_dim = n_dim\n",
    "num_reps = 2\n",
    "num_shots =256 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bc9af-4a1c-453d-be99-d54b9e045628",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ce7078-9255-4913-b6aa-7f05a0e077c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature_map\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=num_reps)\n",
    "\n",
    "# Define the backend\n",
    "backend = QuantumInstance(\n",
    "    BasicAer.get_backend(\"qasm_simulator\"), shots=num_shots, seed_simulator=seed, seed_transpiler=seed\n",
    ")\n",
    "\n",
    "# Define the kernel\n",
    "\n",
    "kernel = QuantumKernel(feature_map=feature_map, quantum_instance=backend)\n",
    "\n",
    "# Model run\n",
    "svc = SVC(kernel=kernel.evaluate)\n",
    "#svc.fit(sample_train, label_train)\n",
    "#score = svc.score(sample_test, label_test)\n",
    "\n",
    "#print(f\"Callable kernel classification test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8fd86d8-bec9-42ac-8543-c69c973a7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_predict = svc.predict(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee71fc2a-46dc-46d1-8f51-8e3df5723407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(label_test,result_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c063aa2-2125-47a9-adf1-ac7f53444551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from tqdm import tqdm\n",
    "def evaluate_ml_model(_models, X, y, n_fold=10, metric='precision'):\n",
    "    ''' Function to evaluate a ML and QML model with a list of metrics\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    results = pd.DataFrame()\n",
    "    kfold = KFold(n_splits=n_fold)\n",
    "    columns = []\n",
    "    for name, model in tqdm(_models):\n",
    "        # -------------------\n",
    "        # Variables initialization \n",
    "        _df = pd.DataFrame()\n",
    "        names = []\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        # -------------------\n",
    "        # k-fold Cross validation\n",
    "        cv_results = cross_validate(model, X, y, cv=kfold, scoring=metric)\n",
    "        \n",
    "        # -------------------\n",
    "        # Compute the mean and standard deviation \n",
    "        for _name, _array in cv_results.items():\n",
    "            names.append(_name)\n",
    "            means.append(round(100*_array.mean(), 2))\n",
    "            stds.append(round(100*_array.std(), 2))\n",
    "        # -------------------\n",
    "        # Save the results in a dataframe \n",
    "        _df =  pd.DataFrame([means, stds], columns=names)\n",
    "        columns.extend([name+' mean (%)', name+' std (%)'])\n",
    "        #results = results.join(_df, on=_df.index)\n",
    "        results = results.append(_df)\n",
    "    results.index = columns\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "627ebe0d-8690-41ec-af85-590018084cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "#models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC()))\n",
    "models.append(('qsvc', svc))\n",
    "_metrics = ['precision', 'recall', 'f1', 'accuracy',  'matthews_corrcoef','balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ce2a3-7a80-42fb-aa8a-80a8da10941a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results = evaluate_ml_model(models, sample_train, label_train, n_fold=10, metric=_metrics)\n",
    "df_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5dd53-d18a-4b66-963f-5fab1974ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(int(len(df_results.index)/2)):\n",
    "\n",
    "    print(f'{df_results.iloc[j].name.split()[0]} & {df_results.iloc[j][2]} ({df_results.iloc[j+1][2]}) & {df_results.iloc[j][3]} ({df_results.iloc[j+1][3]}) &  {df_results.iloc[j][4]} ({df_results.iloc[j+1][4]}) & {df_results.iloc[j][6]} ({df_results.iloc[j+1][6]}) & {df_results.iloc[j][7]} ({df_results.iloc[j+1][7]}) \\\\')\n",
    "    \n",
    "    j+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e6bd91-093f-415f-89b0-40e71ab48126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('LDA_fraud_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70b837-4e39-4b65-83ca-8e82fc83efa1",
   "metadata": {},
   "source": [
    "## Pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff1d5656-f2f2-4d96-b210-a75a161cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ec49f5-c401-4c36-aae3-57aad3eaa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = n_dim\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffcf8fdb-37a0-4b64-b73c-76be553995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "#print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49568595-37ec-4749-a230-dc4c6dae2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.00454489, requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, sample_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4febb380-0955-4f05-a872-326cc4e3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c16a1f84-63e5-4fbb-a647-cba6db4c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07412a53-c93b-4c73-bd0b-e7e144454435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf0b58e-38f3-4c45-a4d2-3d69af787ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ff4aa6-c15b-4a59-a718-67d8da2402dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(-0.08535407, requires_grad=True), tensor(0.34006264, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.70437879, requires_grad=True), tensor(-0.02989927, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.52042413, requires_grad=True), tensor(0.4458723, requires_grad=True)], Y =  1\n",
      "X = [tensor(-0.11997776, requires_grad=True), tensor(0.30784239, requires_grad=True)], Y =  1\n",
      "X = [tensor(0.43129711, requires_grad=True), tensor(0.32273232, requires_grad=True)], Y =  1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(label_train * 2 - np.ones(len(label_train)),requires_grad=True)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(sample_train, requires_grad=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "074f578a-1984-4814-9070-7b20063c8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e0005-464d-46c0-86f4-946291d7586c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d31d6a7-74f4-4e63-b1cb-b92bfb610a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.9146517 | f1: 0.6062407 \n",
      "Iter:     2 | Cost: 1.0271006 | f1: 0.1241379 \n",
      "Iter:     3 | Cost: 0.9447843 | f1: 0.2105263 \n",
      "New best\n",
      "Iter:     4 | Cost: 0.7612764 | f1: 0.6434231 \n",
      "New best\n",
      "Iter:     5 | Cost: 0.7815182 | f1: 0.7495362 \n",
      "New best\n",
      "Iter:     6 | Cost: 0.7493165 | f1: 0.7705882 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.7151832 | f1: 0.8191721 \n",
      "Iter:     8 | Cost: 0.7036907 | f1: 0.7816712 \n",
      "Iter:     9 | Cost: 0.7175986 | f1: 0.7004471 \n",
      "Iter:    10 | Cost: 0.7128700 | f1: 0.7004471 \n",
      "Iter:    11 | Cost: 0.6832924 | f1: 0.8129032 \n",
      "Iter:    12 | Cost: 0.6780496 | f1: 0.8160000 \n",
      "Iter:    13 | Cost: 0.7433835 | f1: 0.7655502 \n",
      "Iter:    14 | Cost: 0.8437661 | f1: 0.7227635 \n",
      "Iter:    15 | Cost: 0.8274103 | f1: 0.7279215 \n",
      "Iter:    16 | Cost: 0.7522588 | f1: 0.7662835 \n",
      "Iter:    17 | Cost: 0.6828545 | f1: 0.8163717 \n",
      "Iter:    18 | Cost: 0.6808797 | f1: 0.7416667 \n",
      "Iter:    19 | Cost: 0.7303683 | f1: 0.6356340 \n",
      "Iter:    20 | Cost: 0.7153637 | f1: 0.6676971 \n",
      "Iter:    21 | Cost: 0.6867502 | f1: 0.7584345 \n",
      "Iter:    22 | Cost: 0.6841801 | f1: 0.8095808 \n",
      "Iter:    23 | Cost: 0.7052322 | f1: 0.8086022 \n",
      "Iter:    24 | Cost: 0.7308755 | f1: 0.7751479 \n",
      "Iter:    25 | Cost: 0.7692515 | f1: 0.7582314 \n",
      "Iter:    26 | Cost: 0.7085764 | f1: 0.7854985 \n",
      "New best\n",
      "Iter:    27 | Cost: 0.6772393 | f1: 0.8207965 \n",
      "Iter:    28 | Cost: 0.6648402 | f1: 0.8188586 \n",
      "Iter:    29 | Cost: 0.6730954 | f1: 0.8046272 \n",
      "Iter:    30 | Cost: 0.6872086 | f1: 0.7471910 \n",
      "Iter:    31 | Cost: 0.7052682 | f1: 0.6808511 \n",
      "Iter:    32 | Cost: 0.6912270 | f1: 0.7342857 \n",
      "Iter:    33 | Cost: 0.6745087 | f1: 0.8192162 \n",
      "Iter:    34 | Cost: 0.6867230 | f1: 0.8122942 \n",
      "Iter:    35 | Cost: 0.7508096 | f1: 0.7640879 \n",
      "Iter:    36 | Cost: 0.8383562 | f1: 0.7246892 \n",
      "Iter:    37 | Cost: 0.8368252 | f1: 0.7253333 \n",
      "Iter:    38 | Cost: 0.7650807 | f1: 0.7570621 \n",
      "Iter:    39 | Cost: 0.6792818 | f1: 0.8173719 \n",
      "Iter:    40 | Cost: 0.6824122 | f1: 0.7510549 \n",
      "Iter:    41 | Cost: 0.6962620 | f1: 0.7032641 \n",
      "Iter:    42 | Cost: 0.6893914 | f1: 0.7468175 \n",
      "Iter:    43 | Cost: 0.6800118 | f1: 0.7905138 \n",
      "Iter:    44 | Cost: 0.6778500 | f1: 0.7813333 \n",
      "Iter:    45 | Cost: 0.6832932 | f1: 0.7468175 \n",
      "Iter:    46 | Cost: 0.6731467 | f1: 0.7840000 \n",
      "Iter:    47 | Cost: 0.6663614 | f1: 0.8202654 \n",
      "Iter:    48 | Cost: 0.6692766 | f1: 0.8150766 \n",
      "New best\n",
      "Iter:    49 | Cost: 0.6733785 | f1: 0.8256881 \n",
      "Iter:    50 | Cost: 0.6785480 | f1: 0.8215488 \n",
      "Iter:    51 | Cost: 0.6795321 | f1: 0.8197088 \n",
      "Iter:    52 | Cost: 0.6717654 | f1: 0.8194444 \n",
      "Iter:    53 | Cost: 0.6650975 | f1: 0.8204489 \n",
      "Iter:    54 | Cost: 0.6680646 | f1: 0.7968545 \n",
      "Iter:    55 | Cost: 0.6667802 | f1: 0.7968545 \n",
      "Iter:    56 | Cost: 0.6699450 | f1: 0.7801609 \n",
      "Iter:    57 | Cost: 0.6604302 | f1: 0.8215159 \n",
      "Iter:    58 | Cost: 0.6773842 | f1: 0.8135224 \n",
      "Iter:    59 | Cost: 0.7511913 | f1: 0.7573182 \n",
      "Iter:    60 | Cost: 0.7851030 | f1: 0.7449541 \n",
      "Iter:    61 | Cost: 0.7967532 | f1: 0.7420237 \n",
      "Iter:    62 | Cost: 0.7678265 | f1: 0.7527881 \n",
      "Iter:    63 | Cost: 0.7062916 | f1: 0.7931034 \n",
      "Iter:    64 | Cost: 0.6683232 | f1: 0.8207547 \n",
      "Iter:    65 | Cost: 0.6894066 | f1: 0.7348703 \n",
      "Iter:    66 | Cost: 0.7232244 | f1: 0.6368000 \n",
      "Iter:    67 | Cost: 0.7815769 | f1: 0.5162455 \n",
      "Iter:    68 | Cost: 0.7828816 | f1: 0.5108696 \n",
      "Iter:    69 | Cost: 0.8115288 | f1: 0.4681648 \n",
      "Iter:    70 | Cost: 0.8546191 | f1: 0.4093567 \n",
      "Iter:    71 | Cost: 0.8182460 | f1: 0.4624060 \n",
      "Iter:    72 | Cost: 0.7348908 | f1: 0.6069652 \n",
      "Iter:    73 | Cost: 0.6922551 | f1: 0.7222222 \n",
      "Iter:    74 | Cost: 0.6809239 | f1: 0.7738420 \n",
      "Iter:    75 | Cost: 0.6754794 | f1: 0.8087855 \n",
      "Iter:    76 | Cost: 0.6731293 | f1: 0.8137755 \n",
      "Iter:    77 | Cost: 0.6693272 | f1: 0.8219178 \n",
      "Iter:    78 | Cost: 0.6722741 | f1: 0.8159437 \n",
      "Iter:    79 | Cost: 0.6693747 | f1: 0.8165680 \n",
      "Iter:    80 | Cost: 0.6794445 | f1: 0.8195991 \n",
      "Iter:    81 | Cost: 0.7065734 | f1: 0.7995889 \n",
      "Iter:    82 | Cost: 0.7040857 | f1: 0.8033126 \n",
      "Iter:    83 | Cost: 0.7066986 | f1: 0.8016444 \n",
      "Iter:    84 | Cost: 0.7121141 | f1: 0.7951318 \n",
      "Iter:    85 | Cost: 0.6809596 | f1: 0.8220994 \n",
      "Iter:    86 | Cost: 0.6668284 | f1: 0.8117798 \n",
      "Iter:    87 | Cost: 0.6868277 | f1: 0.7293777 \n",
      "Iter:    88 | Cost: 0.7175232 | f1: 0.6487342 \n",
      "Iter:    89 | Cost: 0.7587851 | f1: 0.5709343 \n",
      "Iter:    90 | Cost: 0.7451748 | f1: 0.5929648 \n",
      "Iter:    91 | Cost: 0.7055104 | f1: 0.7182482 \n",
      "Iter:    92 | Cost: 0.6939510 | f1: 0.8138639 \n",
      "Iter:    93 | Cost: 0.6972144 | f1: 0.8226779 \n",
      "Iter:    94 | Cost: 0.7013143 | f1: 0.8161850 \n",
      "Iter:    95 | Cost: 0.6945086 | f1: 0.8154206 \n",
      "Iter:    96 | Cost: 0.6820745 | f1: 0.8217822 \n",
      "Iter:    97 | Cost: 0.6794621 | f1: 0.7984190 \n",
      "Iter:    98 | Cost: 0.6757263 | f1: 0.7984190 \n",
      "Iter:    99 | Cost: 0.6718558 | f1: 0.8138639 \n",
      "Iter:   100 | Cost: 0.6712236 | f1: 0.8204489 \n",
      "Iter:   101 | Cost: 0.6792072 | f1: 0.8183962 \n",
      "Iter:   102 | Cost: 0.7020739 | f1: 0.8133047 \n",
      "Iter:   103 | Cost: 0.7211101 | f1: 0.7934893 \n",
      "Iter:   104 | Cost: 0.6958602 | f1: 0.8099891 \n",
      "Iter:   105 | Cost: 0.6787262 | f1: 0.8181818 \n",
      "Iter:   106 | Cost: 0.6654780 | f1: 0.8217822 \n",
      "Iter:   107 | Cost: 0.6640994 | f1: 0.8180678 \n",
      "New best\n",
      "Iter:   108 | Cost: 0.6634609 | f1: 0.8266667 \n",
      "Iter:   109 | Cost: 0.6684679 | f1: 0.8179724 \n",
      "Iter:   110 | Cost: 0.6905406 | f1: 0.8135593 \n",
      "Iter:   111 | Cost: 0.6697428 | f1: 0.8195233 \n",
      "Iter:   112 | Cost: 0.6614063 | f1: 0.8225420 \n",
      "Iter:   113 | Cost: 0.6601402 | f1: 0.8199513 \n",
      "Iter:   114 | Cost: 0.6631332 | f1: 0.8005215 \n",
      "Iter:   115 | Cost: 0.6794163 | f1: 0.7417974 \n",
      "Iter:   116 | Cost: 0.7307364 | f1: 0.6092715 \n",
      "Iter:   117 | Cost: 0.7447060 | f1: 0.6073826 \n",
      "Iter:   118 | Cost: 0.7257525 | f1: 0.6254072 \n",
      "Iter:   119 | Cost: 0.6663804 | f1: 0.7836412 \n",
      "Iter:   120 | Cost: 0.6616989 | f1: 0.8166667 \n",
      "Iter:   121 | Cost: 0.6613048 | f1: 0.8191617 \n",
      "Iter:   122 | Cost: 0.6610759 | f1: 0.8080301 \n",
      "Iter:   123 | Cost: 0.6656221 | f1: 0.7853403 \n",
      "Iter:   124 | Cost: 0.6771439 | f1: 0.7405330 \n",
      "Iter:   125 | Cost: 0.7028708 | f1: 0.6748092 \n",
      "Iter:   126 | Cost: 0.6946372 | f1: 0.6947368 \n",
      "Iter:   127 | Cost: 0.6683241 | f1: 0.7625509 \n",
      "Iter:   128 | Cost: 0.6599811 | f1: 0.8141176 \n",
      "Iter:   129 | Cost: 0.7181568 | f1: 0.7778875 \n",
      "Iter:   130 | Cost: 0.7446020 | f1: 0.7689358 \n",
      "Iter:   131 | Cost: 0.7551659 | f1: 0.7601896 \n",
      "Iter:   132 | Cost: 0.7709936 | f1: 0.7516279 \n",
      "Iter:   133 | Cost: 0.7596400 | f1: 0.7570621 \n",
      "Iter:   134 | Cost: 0.7891485 | f1: 0.7467890 \n",
      "Iter:   135 | Cost: 0.8475452 | f1: 0.7202118 \n",
      "Iter:   136 | Cost: 0.7710242 | f1: 0.7511563 \n",
      "Iter:   137 | Cost: 0.6786556 | f1: 0.8240535 \n",
      "Iter:   138 | Cost: 0.6703696 | f1: 0.8136882 \n",
      "Iter:   139 | Cost: 0.6684413 | f1: 0.8020833 \n",
      "Iter:   140 | Cost: 0.6621903 | f1: 0.8138639 \n",
      "Iter:   141 | Cost: 0.6569097 | f1: 0.8184019 \n",
      "Iter:   142 | Cost: 0.6766810 | f1: 0.8157034 \n",
      "Iter:   143 | Cost: 0.6934028 | f1: 0.8104712 \n",
      "Iter:   144 | Cost: 0.7042161 | f1: 0.7955239 \n",
      "Iter:   145 | Cost: 0.6720835 | f1: 0.8191964 \n",
      "Iter:   146 | Cost: 0.6626910 | f1: 0.8186047 \n",
      "Iter:   147 | Cost: 0.6579483 | f1: 0.8229426 \n",
      "Iter:   148 | Cost: 0.6689778 | f1: 0.7723577 \n",
      "Iter:   149 | Cost: 0.6826915 | f1: 0.7338129 \n",
      "Iter:   150 | Cost: 0.7031558 | f1: 0.6779141 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 0 \n",
    "for it in range(150):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.f1_score(Y, predictions, average='binary', pos_label=1)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print('New best')\n",
    "    #prec = metrics.precision_score(Y, predictions, average='binary')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee2dceeb-5b76-4ec7-9ebb-efb9e562cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(label_test * 2 - np.ones(len(label_test)))\n",
    "Xte = np.array(normalize(sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03ecd991-b560-4868-9e42-1dcfe09d58ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    112\n",
       "-1.0     88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Yte).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4416ed73-4c7d-44e3-a539-9dba3191327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.7482889902426437, Accuracy: 73.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4a2955a-d877-4885-ad84-5f31458a7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.70      0.69      0.70        90\n",
      "         1.0       0.75      0.76      0.76       110\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.73      0.73       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcedeada-a82f-4e82-b738-6a862dc801c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 75.0%\n",
      "    Recall: 76.36%\n",
      "    f1: 75.68%\n",
      "    Accuracy: 73.0%\n",
      "    Balanced accuracy: 72.63%\n",
      "    Matthew corcorref: 45.35%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77acf9e4-6362-4daa-829c-a5c70138be5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 1.0067215 | f1: 0.6343356 \n",
      "Iter:     2 | Cost: 0.9723392 | f1: 0.4594181 \n",
      "Iter:     3 | Cost: 0.9288479 | f1: 0.6085754 \n",
      "Iter:     4 | Cost: 0.8918161 | f1: 0.5893720 \n",
      "Iter:     5 | Cost: 0.8525129 | f1: 0.6171244 \n",
      "New best\n",
      "Iter:     6 | Cost: 0.8058089 | f1: 0.7450980 \n",
      "Iter:     7 | Cost: 0.7761323 | f1: 0.7324750 \n",
      "New best\n",
      "Iter:     8 | Cost: 0.7428069 | f1: 0.7917206 \n",
      "Iter:     9 | Cost: 0.7662221 | f1: 0.7660415 \n",
      "Iter:    10 | Cost: 0.8084035 | f1: 0.7406049 \n",
      "Iter:    11 | Cost: 0.8446540 | f1: 0.7136564 \n",
      "Iter:    12 | Cost: 0.8359626 | f1: 0.7246637 \n",
      "Iter:    13 | Cost: 0.7680303 | f1: 0.7643678 \n",
      "New best\n",
      "Iter:    14 | Cost: 0.7002655 | f1: 0.8077336 \n",
      "Iter:    15 | Cost: 0.6693473 | f1: 0.8020050 \n",
      "Iter:    16 | Cost: 0.6806609 | f1: 0.7362482 \n",
      "Iter:    17 | Cost: 0.7140716 | f1: 0.6562986 \n",
      "Iter:    18 | Cost: 0.7155379 | f1: 0.6456693 \n",
      "Iter:    19 | Cost: 0.7144937 | f1: 0.6425197 \n",
      "Iter:    20 | Cost: 0.6733834 | f1: 0.7786667 \n",
      "New best\n",
      "Iter:    21 | Cost: 0.6683179 | f1: 0.8176255 \n",
      "Iter:    22 | Cost: 0.6695398 | f1: 0.8129496 \n",
      "New best\n",
      "Iter:    23 | Cost: 0.6859641 | f1: 0.8188804 \n",
      "Iter:    24 | Cost: 0.6936737 | f1: 0.8085561 \n",
      "Iter:    25 | Cost: 0.6983294 | f1: 0.7991588 \n",
      "Iter:    26 | Cost: 0.6753946 | f1: 0.8168373 \n",
      "Iter:    27 | Cost: 0.6801469 | f1: 0.7548209 \n",
      "Iter:    28 | Cost: 0.6983109 | f1: 0.7051852 \n",
      "Iter:    29 | Cost: 0.7074595 | f1: 0.6828528 \n",
      "Iter:    30 | Cost: 0.6775939 | f1: 0.7984694 \n",
      "Iter:    31 | Cost: 0.6779025 | f1: 0.8139256 \n",
      "Iter:    32 | Cost: 0.6951305 | f1: 0.8187773 \n",
      "Iter:    33 | Cost: 0.7452600 | f1: 0.7750730 \n",
      "Iter:    34 | Cost: 0.8434292 | f1: 0.7214854 \n",
      "Iter:    35 | Cost: 0.7853245 | f1: 0.7527881 \n",
      "Iter:    36 | Cost: 0.7681156 | f1: 0.7577757 \n",
      "Iter:    37 | Cost: 0.7203036 | f1: 0.7794263 \n",
      "Iter:    38 | Cost: 0.6963798 | f1: 0.8029197 \n",
      "New best\n",
      "Iter:    39 | Cost: 0.6776182 | f1: 0.8194906 \n",
      "New best\n",
      "Iter:    40 | Cost: 0.6728042 | f1: 0.8227273 \n",
      "Iter:    41 | Cost: 0.6669088 | f1: 0.8209501 \n",
      "Iter:    42 | Cost: 0.6856763 | f1: 0.7396871 \n",
      "Iter:    43 | Cost: 0.7547063 | f1: 0.5831904 \n",
      "Iter:    44 | Cost: 0.7896796 | f1: 0.4898711 \n",
      "Iter:    45 | Cost: 0.8248297 | f1: 0.4397706 \n",
      "Iter:    46 | Cost: 0.8099111 | f1: 0.4719101 \n",
      "Iter:    47 | Cost: 0.7845174 | f1: 0.5063752 \n",
      "Iter:    48 | Cost: 0.7152088 | f1: 0.6434231 \n",
      "Iter:    49 | Cost: 0.6736749 | f1: 0.7616438 \n",
      "Iter:    50 | Cost: 0.6680610 | f1: 0.7894737 \n",
      "Iter:    51 | Cost: 0.6642725 | f1: 0.8186275 \n",
      "Iter:    52 | Cost: 0.6644250 | f1: 0.8091024 \n",
      "Iter:    53 | Cost: 0.6842881 | f1: 0.7338129 \n",
      "Iter:    54 | Cost: 0.7220732 | f1: 0.6379585 \n",
      "Iter:    55 | Cost: 0.7208772 | f1: 0.6455696 \n",
      "Iter:    56 | Cost: 0.6978109 | f1: 0.7004471 \n",
      "Iter:    57 | Cost: 0.6869146 | f1: 0.7371429 \n",
      "Iter:    58 | Cost: 0.6745286 | f1: 0.7783641 \n",
      "Iter:    59 | Cost: 0.6707107 | f1: 0.8108108 \n",
      "Iter:    60 | Cost: 0.6700957 | f1: 0.8177458 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew best\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#prec = metrics.precision_score(Y, predictions, average='binary')\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIter: \u001b[39m\u001b[38;5;132;01m{:5d}\u001b[39;00m\u001b[38;5;124m | Cost: \u001b[39m\u001b[38;5;132;01m{:0.7f}\u001b[39;00m\u001b[38;5;124m | f1: \u001b[39m\u001b[38;5;132;01m{:0.7f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m---> 43\u001b[0m         it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m, prec\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m )\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(weights, bias, X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(weights, bias, X, Y):\n\u001b[0;32m----> 2\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [variational_classifier(weights, bias, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m square_loss(Y, predictions)\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(weights, bias, X, Y):\n\u001b[0;32m----> 2\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mvariational_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m square_loss(Y, predictions)\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mvariational_classifier\u001b[0;34m(weights, bias, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariational_classifier\u001b[39m(weights, bias, x):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/qnode.py:660\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m             res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(res)\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 660\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m autograd\u001b[38;5;241m.\u001b[39misinstance(res, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m# If a device batch transform was applied, we need to 'unpack'\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;66;03m# the returned tuple/list to a float.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO: find a more explicit way of determining that a batch transform\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;66;03m# was applied.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m     res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/interfaces/execution.py:370\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_fn(res)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_fn(\n\u001b[0;32m--> 370\u001b[0m         \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterfaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_execute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_fn\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# the default execution function is batch_execute\u001b[39;00m\n\u001b[1;32m    376\u001b[0m execute_fn \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39minterfaces\u001b[38;5;241m.\u001b[39mcache_execute(batch_execute, cache, expand_fn\u001b[38;5;241m=\u001b[39mexpand_fn)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/interfaces/execution.py:197\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecution_tapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m final_res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/interfaces/execution.py:122\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(tapes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m [expand_fn(tape) \u001b[38;5;28;01mfor\u001b[39;00m tape \u001b[38;5;129;01min\u001b[39;00m tapes]\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/_qubit_device.py:576\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# TODO: Insert control on value here\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/_qubit_device.py:310\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_validity(circuit\u001b[38;5;241m.\u001b[39moperations, circuit\u001b[38;5;241m.\u001b[39mobservables)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# apply all circuit operations\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiagonalizing_gates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# generate computational basis samples\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mis_sampled:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:255\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debugger\u001b[38;5;241m.\u001b[39msnapshots[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debugger\u001b[38;5;241m.\u001b[39msnapshots)] \u001b[38;5;241m=\u001b[39m state_vector\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# store the pre-rotated state\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_rotated_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:283\u001b[0m, in \u001b[0;36mDefaultQubit._apply_operation\u001b[0;34m(self, state, operation)\u001b[0m\n\u001b[1;32m    280\u001b[0m     axes \u001b[38;5;241m=\u001b[39m [ax \u001b[38;5;241m+\u001b[39m shift \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires\u001b[38;5;241m.\u001b[39mindices(wires)]\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_ops[operation\u001b[38;5;241m.\u001b[39mbase_name](state, axes, inverse\u001b[38;5;241m=\u001b[39moperation\u001b[38;5;241m.\u001b[39minverse)\n\u001b[0;32m--> 283\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unitary_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_DTYPE)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m operation \u001b[38;5;129;01min\u001b[39;00m diagonal_in_z_basis:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_diagonal_unitary(state, matrix, wires)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:617\u001b[0m, in \u001b[0;36mDefaultQubit._get_unitary_matrix\u001b[0;34m(self, unitary)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unitary \u001b[38;5;129;01min\u001b[39;00m diagonal_in_z_basis:\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unitary\u001b[38;5;241m.\u001b[39meigvals()\n\u001b[0;32m--> 617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munitary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/operation.py:1486\u001b[0m, in \u001b[0;36mOperation.matrix\u001b[0;34m(self, wire_order)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, wire_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1486\u001b[0m     canonical_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse:\n\u001b[1;32m   1489\u001b[0m         canonical_matrix \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mconj(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mmoveaxis(canonical_matrix, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/ops/qubit/parametric_ops.py:782\u001b[0m, in \u001b[0;36mRot.compute_matrix\u001b[0;34m(phi, theta, omega)\u001b[0m\n\u001b[1;32m    769\u001b[0m s \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m*\u001b[39m one\n\u001b[1;32m    771\u001b[0m mat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    772\u001b[0m     [\n\u001b[1;32m    773\u001b[0m         qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39mj \u001b[38;5;241m*\u001b[39m (phi \u001b[38;5;241m+\u001b[39m omega)) \u001b[38;5;241m*\u001b[39m c,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m     ],\n\u001b[1;32m    780\u001b[0m ]\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mstack([stack_last(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m mat], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/ops/qubit/parametric_ops.py:782\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    769\u001b[0m s \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m*\u001b[39m one\n\u001b[1;32m    771\u001b[0m mat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    772\u001b[0m     [\n\u001b[1;32m    773\u001b[0m         qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39mj \u001b[38;5;241m*\u001b[39m (phi \u001b[38;5;241m+\u001b[39m omega)) \u001b[38;5;241m*\u001b[39m c,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m     ],\n\u001b[1;32m    780\u001b[0m ]\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mstack([\u001b[43mstack_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m mat], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/math/multi_dispatch.py:178\u001b[0m, in \u001b[0;36mmulti_dispatch.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m interface \u001b[38;5;241m=\u001b[39m interface \u001b[38;5;129;01mor\u001b[39;00m _multi_dispatch(dispatch_args)\n\u001b[1;32m    176\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlike\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m interface\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/math/multi_dispatch.py:507\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(values, axis, like)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m\"\"\"Stack a sequence of tensors along the specified axis.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m.. warning::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m       [5.00e+00, 8.00e+00, 1.01e+02]], dtype=float32)>\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    506\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcoerce(values, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlike\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autoray/autoray.py:85\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     backend \u001b[38;5;241m=\u001b[39m infer_backend(like)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_lib_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pennylane/numpy/wrapper.py:117\u001b[0m, in \u001b[0;36mtensor_wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         tensor_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39many([i\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tensor_args])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# evaluate the original object\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, _np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# only if the output of the object is a ndarray,\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# then convert to a PennyLane tensor\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     res \u001b[38;5;241m=\u001b[39m tensor(res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/numpy/numpy_wrapper.py:88\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# this code is basically copied from numpy/core/shape_base.py's stack\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# we need it here because we want to re-implement stack in terms of the\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# primitives defined in this file\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [array(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/numpy/numpy_wrapper.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# this code is basically copied from numpy/core/shape_base.py's stack\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# we need it here because we want to re-implement stack in terms of the\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# primitives defined in this file\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/numpy/numpy_wrapper.py:60\u001b[0m, in \u001b[0;36marray\u001b[0;34m(A, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_from_args(args, kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(array, A))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_from_scalar_or_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/tracer.py:37\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f_raw)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 37\u001b[0m     boxed_args, trace, node_constructor \u001b[38;5;241m=\u001b[39m \u001b[43mfind_top_boxed_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m boxed_args:\n\u001b[1;32m     39\u001b[0m         argvals \u001b[38;5;241m=\u001b[39m subvals(args, [(argnum, box\u001b[38;5;241m.\u001b[39m_value) \u001b[38;5;28;01mfor\u001b[39;00m argnum, box \u001b[38;5;129;01min\u001b[39;00m boxed_args])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/tracer.py:70\u001b[0m, in \u001b[0;36mfind_top_boxed_args\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m top_node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m argnum, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     71\u001b[0m         trace \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_trace\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m trace \u001b[38;5;241m>\u001b[39m top_trace:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/autograd/tracer.py:123\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt differentiate w.r.t. type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(value)))\n\u001b[1;32m    122\u001b[0m box_types \u001b[38;5;241m=\u001b[39m Box\u001b[38;5;241m.\u001b[39mtypes\n\u001b[0;32m--> 123\u001b[0m isbox  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;129;01min\u001b[39;00m box_types  \u001b[38;5;66;03m# almost 3X faster than isinstance(x, Box)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m getval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: getval(x\u001b[38;5;241m.\u001b[39m_value) \u001b[38;5;28;01mif\u001b[39;00m isbox(x) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 1 \n",
    "for it in range(150):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.f1_score(Y, predictions, average='binary', pos_label=1)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print('New best')\n",
    "    #prec = metrics.precision_score(Y, predictions, average='binary')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "615e6410-5955-469d-8ccd-32517ba8ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.4650416259302474, Accuracy: 86.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "694c231f-ce47-4bdb-be6a-eb1308ebc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.85      1.00      0.92       154\n",
      "         1.0       1.00      0.41      0.58        46\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.93      0.71      0.75       200\n",
      "weighted avg       0.89      0.86      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Yte, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "660c69a6-87da-400e-99ba-739d49627088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 41.3%\n",
      "    Recall: 100.0%\n",
      "    f1: 58.46%\n",
      "    Accuracy: 86.5%\n",
      "    Balanced accuracy: 92.54%\n",
      "    Matthew corcorref: 59.28%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee63f17-2adf-48b6-9106-fb542ed641d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
