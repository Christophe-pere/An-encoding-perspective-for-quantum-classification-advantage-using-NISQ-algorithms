{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pennylane import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane_qiskit import IBMQDevice\n",
    "from pennylane_qiskit import BasicAerDevice\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import normalize\n",
    "from skpp import ProjectionPursuitRegressor\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset CSV load\n",
    "df = pd.read_csv('fraud_detection_bank_dataset.csv', sep=',')\n",
    "\n",
    "# Data type definition as float\n",
    "df = df.astype(float)\n",
    "\n",
    "# Drop of columns if necessary\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Sample selection\n",
    "df_sample = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 8912 to 5204\n",
      "Columns: 113 entries, col_0 to targets\n",
      "dtypes: float64(113)\n",
      "memory usage: 890.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Review the information related to the dataframe\n",
    "\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.635000</td>\n",
       "      <td>267.685000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>2.01500</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>2.367000</td>\n",
       "      <td>2.635000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>41.659000</td>\n",
       "      <td>0.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.759254</td>\n",
       "      <td>692.297183</td>\n",
       "      <td>2.610063</td>\n",
       "      <td>6.97032</td>\n",
       "      <td>0.466006</td>\n",
       "      <td>1.796266</td>\n",
       "      <td>2.999218</td>\n",
       "      <td>11.759254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>0.479947</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.389301</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.224966</td>\n",
       "      <td>53.091915</td>\n",
       "      <td>0.446232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>239.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>234.000000</td>\n",
       "      <td>9319.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>183.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col_0        col_1        col_2       col_3        col_4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.00000  1000.000000   \n",
       "mean      2.635000   267.685000     0.372000     2.01500     0.084000   \n",
       "std      11.759254   692.297183     2.610063     6.97032     0.466006   \n",
       "min       0.000000     0.000000     0.000000     0.00000     0.000000   \n",
       "25%       0.000000    36.000000     0.000000     0.00000     0.000000   \n",
       "50%       0.000000    96.000000     0.000000     1.00000     0.000000   \n",
       "75%       1.000000   239.250000     0.000000     2.00000     0.000000   \n",
       "max     234.000000  9319.000000    48.000000   183.00000     9.000000   \n",
       "\n",
       "             col_5        col_6        col_7   col_8   col_9  ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.0  1000.0  ...   \n",
       "mean      0.784000     2.367000     2.635000     0.0     0.0  ...   \n",
       "std       1.796266     2.999218    11.759254     0.0     0.0  ...   \n",
       "min       0.000000    -1.000000     0.000000     0.0     0.0  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.0     0.0  ...   \n",
       "50%       0.000000     2.000000     0.000000     0.0     0.0  ...   \n",
       "75%       1.000000     6.000000     1.000000     0.0     0.0  ...   \n",
       "max      38.000000     8.000000   234.000000     0.0     0.0  ...   \n",
       "\n",
       "           col_103      col_104      col_105      col_106      col_107  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.005000     0.359000     0.003000     0.303000     0.186000   \n",
       "std       0.070569     0.479947     0.054717     0.459785     0.389301   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           col_108      col_109      col_110      col_111      targets  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.001000     0.047000     0.021000    41.659000     0.274000  \n",
       "std       0.031623     0.211745     0.224966    53.091915     0.446232  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     5.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000    18.500000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000    60.000000     1.000000  \n",
       "max       1.000000     1.000000     5.000000   485.000000     1.000000  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of the description of the dataframe related to fixed parameters\n",
    "\n",
    "df_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test and validation split\n",
    "train = df_sample.sample(frac = 0.7)\n",
    "test = df_sample.drop(train.index)\n",
    "#validate = df_sample.drop(train.index).drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 113)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 113)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 113)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of labels\n",
    "x_train = train\n",
    "y_train = train[['targets']]\n",
    "x_test = test\n",
    "y_test = test[['targets']]\n",
    "#x_validate = validate\n",
    "#y_validate = validate[['targets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['targets'], axis = 1)\n",
    "x_test = x_test.drop(['targets'], axis = 1)\n",
    "#x_validate = x_validate.drop(['targets'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_102</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20020</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6898</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13819</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15944</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "5154    True  False   True  False   True  False  False   True   True   True   \n",
       "94     False  False  False   True  False   True  False  False   True   True   \n",
       "20020  False  False   True  False   True   True  False  False   True   True   \n",
       "15278   True  False  False   True   True   True  False   True   True   True   \n",
       "8116    True  False   True   True  False   True  False   True   True   True   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "6683   False  False   True  False   True  False  False  False   True   True   \n",
       "6898    True  False   True  False   True   True  False   True   True   True   \n",
       "13819   True  False   True  False   True   True  False   True   True   True   \n",
       "10367   True  False  False   True   True   True  False   True   True   True   \n",
       "15944   True  False   True  False   True   True  False   True   True   True   \n",
       "\n",
       "       ...  col_102  col_103  col_104  col_105  col_106  col_107  col_108  \\\n",
       "5154   ...     True     True     True     True     True     True     True   \n",
       "94     ...     True     True    False     True     True     True     True   \n",
       "20020  ...    False     True     True     True     True     True     True   \n",
       "15278  ...    False     True    False     True    False    False     True   \n",
       "8116   ...     True     True    False     True     True     True     True   \n",
       "...    ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "6683   ...    False     True     True     True    False     True     True   \n",
       "6898   ...    False     True     True     True     True     True     True   \n",
       "13819  ...    False     True     True     True     True     True     True   \n",
       "10367  ...     True     True     True     True     True     True     True   \n",
       "15944  ...     True     True     True     True     True     True     True   \n",
       "\n",
       "       col_109  col_110  col_111  \n",
       "5154      True     True    False  \n",
       "94       False     True    False  \n",
       "20020     True     True    False  \n",
       "15278     True     True    False  \n",
       "8116      True     True    False  \n",
       "...        ...      ...      ...  \n",
       "6683      True     True    False  \n",
       "6898      True     True    False  \n",
       "13819     True     True    False  \n",
       "10367     True     True    False  \n",
       "15944     True     True     True  \n",
       "\n",
       "[700 rows x 112 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_0      False\n",
       "col_1      False\n",
       "col_2      False\n",
       "col_3      False\n",
       "col_4      False\n",
       "           ...  \n",
       "col_107    False\n",
       "col_108     True\n",
       "col_109    False\n",
       "col_110    False\n",
       "col_111    False\n",
       "Length: 112, dtype: bool"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_0 = x_train.columns[(x_train == 0).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_18', 'col_19',\n",
       "       'col_20', 'col_21', 'col_35', 'col_39', 'col_40', 'col_51', 'col_52',\n",
       "       'col_53', 'col_58', 'col_70', 'col_71', 'col_78', 'col_91', 'col_93',\n",
       "       'col_108'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = x_train.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col_7', 'col_22', 'col_54', 'col_61']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>...</th>\n",
       "      <th>col_102</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18971</th>\n",
       "      <td>9.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>1.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_13  col_14  \\\n",
       "9033     1.0  109.0    0.0    5.0    0.0    0.0    2.0     0.0     1.0   \n",
       "4901     0.0   10.0    0.0    0.0    0.0    1.0    5.0     0.0     0.0   \n",
       "3139     0.0   29.0    0.0    0.0    0.0    1.0    0.0     0.0     0.0   \n",
       "10730    0.0   13.0    0.0    1.0    0.0    0.0   -1.0     0.0     0.0   \n",
       "18971    9.0  309.0    3.0    1.0    0.0    0.0   -1.0     0.0     0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...     ...     ...   \n",
       "4531     0.0   99.0    0.0    1.0    0.0    2.0    0.0     0.0     1.0   \n",
       "10515    0.0   79.0    0.0    2.0    0.0    0.0    0.0     0.0     1.0   \n",
       "12659    0.0  109.0    0.0    3.0    0.0    0.0    6.0     0.0     0.0   \n",
       "4623     1.0  341.0    0.0    0.0    0.0    3.0    2.0     0.0     0.0   \n",
       "15376    0.0   87.0    0.0    2.0    0.0    0.0    0.0     0.0     0.0   \n",
       "\n",
       "       col_15  ...  col_102  col_103  col_104  col_105  col_106  col_107  \\\n",
       "9033      1.0  ...      1.0      0.0      1.0      0.0      0.0      0.0   \n",
       "4901      0.0  ...      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "3139      0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10730     0.0  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "18971     1.0  ...      0.0      0.0      0.0      0.0      1.0      1.0   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "4531      0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10515     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "12659     0.0  ...      0.0      0.0      0.0      0.0      1.0      1.0   \n",
       "4623      1.0  ...      1.0      0.0      1.0      0.0      0.0      0.0   \n",
       "15376     0.0  ...      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "       col_108  col_109  col_110  col_111  \n",
       "9033       0.0      0.0      0.0     60.0  \n",
       "4901       0.0      0.0      0.0     65.0  \n",
       "3139       0.0      0.0      0.0      0.0  \n",
       "10730      0.0      0.0      0.0      7.0  \n",
       "18971      0.0      0.0      0.0     14.0  \n",
       "...        ...      ...      ...      ...  \n",
       "4531       0.0      1.0      0.0     40.0  \n",
       "10515      0.0      0.0      0.0      0.0  \n",
       "12659      0.0      0.0      0.0     20.0  \n",
       "4623       0.0      0.0      0.0     68.0  \n",
       "15376      0.0      0.0      0.0     45.0  \n",
       "\n",
       "[150 rows x 93 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.drop(['col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_18', 'col_19','col_20', 'col_21', 'col_35', 'col_51', 'col_52', 'col_53', 'col_70','col_71','col_7', 'col_22', 'col_54', 'col_56'], axis = 1)\n",
    "x_test.drop(['col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_18', 'col_19','col_20', 'col_21', 'col_35', 'col_51', 'col_52', 'col_53', 'col_70','col_71','col_7', 'col_22', 'col_54', 'col_56'], axis = 1)\n",
    "x_validate.drop(['col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_18', 'col_19','col_20', 'col_21', 'col_35', 'col_51', 'col_52', 'col_53', 'col_70','col_71','col_7', 'col_22', 'col_54', 'col_56'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "skpp = ProjectionPursuitRegressor(r=2, fit_type='spline').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA validate transformation (using train fit)\n",
    "x_train_skpp = skpp.transform(x_train)\n",
    "x_test_skpp = skpp.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to dataframe for join in a single df\n",
    "x_train_skpp = pd.DataFrame(x_train_skpp)\n",
    "x_test_skpp = pd.DataFrame(x_test_skpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second standard scaler normalization (using train fit)\n",
    "std_scale = StandardScaler().fit(x_train_skpp)\n",
    "data = std_scale.transform(x_train_skpp)\n",
    "x_test_lda_n = std_scale.transform(x_test_skpp)\n",
    "#x_validate_lda_n = std_scale.transform(x_validate_skpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions definition for QML\n",
    "n_dim = len(x_train_skpp.columns)\n",
    "n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targets\n",
       "0.0        72.285714\n",
       "1.0        27.714286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the balance of the target variable in train\n",
    "\n",
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targets\n",
       "0.0        73.333333\n",
       "1.0        26.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the balance of the target variable in test\n",
    "\n",
    "y_test.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin of Pennylane variational classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "num_qubits = n_dim\n",
    "\n",
    "# Device seletion\n",
    "dev = qml.device('default.qubit', wires = num_qubits, shots=1024)\n",
    "#dev = qml.device('lightning.qubit',wires=1)\n",
    "#dev = qml.device('default.qubit.tf', wires = num_qubits, shots=1024)\n",
    "#dev = qml.device('qiskit.ibmq', wires = num_qubits, backend='ibmq_manila', ibmqx_token=\"6cc75c58fc80fea56cb8dd391f8fbcfdb676a3dc7005493728bc9da7ea753e31a2110a01e3a0cc83f1a98f5ca79e32956fc66c11b5eea4cae163b3fa996be356\", shots=256)\n",
    "#dev = qml.device('qiskit.basicaer', wires = num_qubits, shots = 256)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-3.22670552e-03 -1.07100838e-02 -1.28722659e-03]\n",
      "  [ 9.31083045e-03  8.09626772e-03 -1.08806313e-02]]\n",
      "\n",
      " [[ 1.76780686e-02 -1.85177689e-02  2.79278253e-03]\n",
      "  [-1.42404580e-02  1.15278274e-02 -6.16505446e-03]]\n",
      "\n",
      " [[ 4.86041831e-03 -5.22699780e-03  9.15000609e-03]\n",
      "  [ 8.21095090e-03  1.32754053e-02 -9.95269171e-03]]\n",
      "\n",
      " [[ 4.15453097e-03  1.13071398e-02 -4.42821579e-03]\n",
      "  [ 6.36920817e-04 -9.89950779e-03 -3.38427651e-03]]\n",
      "\n",
      " [[-2.36630327e-03  1.74899636e-02  6.79042991e-05]\n",
      "  [ 1.15500310e-04  1.69366437e-02 -5.46363156e-03]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.20703125, requires_grad=True)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(-0.82001632, requires_grad=False), tensor(0.23429635, requires_grad=False)], Y =  1\n",
      "X = [tensor(-0.98184432, requires_grad=False), tensor(0.16750821, requires_grad=False)], Y =  1\n",
      "X = [tensor(0.3377696, requires_grad=False), tensor(-0.38331004, requires_grad=False)], Y = -1\n",
      "X = [tensor(1.70523133, requires_grad=False), tensor(1.20413485, requires_grad=False)], Y = -1\n",
      "X = [tensor(-0.6980282, requires_grad=False), tensor(-0.27874216, requires_grad=False)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(y_train.values[:,0] * 2 - np.ones(len(y_train.values[:,0])), requires_grad = False)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(data, requires_grad=False)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.7722841 | Accuracy: 0.7157143 \n",
      "New best\n",
      "Iter:     2 | Cost: 0.6712983 | Accuracy: 0.7357143 \n",
      "New best\n",
      "Iter:     3 | Cost: 0.6190105 | Accuracy: 0.7457143 \n",
      "New best\n",
      "Iter:     4 | Cost: 0.5452505 | Accuracy: 0.8014286 \n",
      "New best\n",
      "Iter:     5 | Cost: 0.5651728 | Accuracy: 0.8185714 \n",
      "New best\n",
      "Iter:     6 | Cost: 0.5162663 | Accuracy: 0.8585714 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.4820346 | Accuracy: 0.8771429 \n",
      "Iter:     8 | Cost: 0.4716927 | Accuracy: 0.8471429 \n",
      "Iter:     9 | Cost: 0.4767313 | Accuracy: 0.8400000 \n",
      "Iter:    10 | Cost: 0.4972898 | Accuracy: 0.8271429 \n",
      "Iter:    11 | Cost: 0.5203754 | Accuracy: 0.7971429 \n",
      "Iter:    12 | Cost: 0.5550295 | Accuracy: 0.7500000 \n",
      "Iter:    13 | Cost: 0.5444372 | Accuracy: 0.7514286 \n",
      "Iter:    14 | Cost: 0.5009727 | Accuracy: 0.8428571 \n",
      "New best\n",
      "Iter:    15 | Cost: 0.5475504 | Accuracy: 0.8957143 \n",
      "Iter:    16 | Cost: 0.5252286 | Accuracy: 0.8900000 \n",
      "Iter:    17 | Cost: 0.4738357 | Accuracy: 0.8957143 \n",
      "Iter:    18 | Cost: 0.4790248 | Accuracy: 0.8342857 \n",
      "Iter:    19 | Cost: 0.4866500 | Accuracy: 0.8157143 \n",
      "Iter:    20 | Cost: 0.4815414 | Accuracy: 0.8214286 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "\n",
    "for it in range(20):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set preparation\n",
    "Yte = np.array(y_test.values[:,0] * 2 - np.ones(len(y_test.values[:,0])), requires_grad = False)\n",
    "Xte = np.array(normalize(x_test_lda_n), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.6148822025971983, Accuracy: 79.0%\n"
     ]
    }
   ],
   "source": [
    "# Outcome on test set\n",
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test Predictions\n",
       "0    -1.0        -1.0\n",
       "1    -1.0        -1.0\n",
       "2    -1.0        -1.0\n",
       "3    -1.0        -1.0\n",
       "4    -1.0         1.0\n",
       "..    ...         ...\n",
       "295  -1.0        -1.0\n",
       "296  -1.0        -1.0\n",
       "297   1.0        -1.0\n",
       "298  -1.0        -1.0\n",
       "299   1.0         1.0\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test and predictions comparison\n",
    "pd.DataFrame((Yte, predictions), ('Test', 'Predictions')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.91      0.80      0.85       220\n",
      "         1.0       0.58      0.78      0.66        80\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.74      0.79      0.76       300\n",
      "weighted avg       0.82      0.79      0.80       300\n",
      "\n",
      "0.5794392523364486\n",
      "0.775\n",
      "0.6631016042780749\n",
      "0.7852272727272727\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report and important metrics\n",
    "print(metrics.classification_report(Yte, predictions))\n",
    "print(metrics.precision_score(Yte, predictions))\n",
    "print(metrics.recall_score(Yte, predictions))\n",
    "print(metrics.f1_score(Yte, predictions))\n",
    "print(metrics.balanced_accuracy_score(Yte, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16503906 0.34960938 0.21875    0.49609375 0.73242188 0.18261719\n",
      " 0.21777344 0.21777344 0.35644531 0.76757812 0.10742188 0.25097656\n",
      " 0.08398438 0.19335938 0.52148438 0.17675781 0.09765625 0.57714844\n",
      " 0.74316406 0.52636719 0.0703125  0.703125   0.50585938 0.5625\n",
      " 0.09082031 0.09375    0.51953125 0.36914062 0.09863281 0.20996094\n",
      " 0.76953125 0.64550781 0.11328125 0.55175781 0.52246094 0.74609375\n",
      " 0.18457031 0.46777344 0.46484375 0.68554688 0.67285156 0.71679688\n",
      " 0.75292969 0.56738281 0.10644531 0.75585938 0.58300781 0.12890625\n",
      " 0.3046875  0.24316406 0.60058594 0.57714844 0.22363281 0.65332031\n",
      " 0.67089844 0.47363281 0.56738281 0.59375    0.69433594 0.21289063\n",
      " 0.10253906 0.2578125  0.09863281 0.22753906 0.37011719 0.29492188\n",
      " 0.22265625 0.10449219 0.14550781 0.19140625 0.41796875 0.10644531\n",
      " 0.7265625  0.37988281 0.74121094 0.29589844 0.09570313 0.12695313\n",
      " 0.75292969 0.18261719 0.27246094 0.3671875  0.09082031 0.61816406\n",
      " 0.36621094 0.28320312 0.46582031 0.10058594 0.6015625  0.10449219\n",
      " 0.74707031 0.75195312 0.74511719 0.76757812 0.76953125 0.76757812\n",
      " 0.56835938 0.0703125  0.09277344 0.08398438 0.36816406 0.66210938\n",
      " 0.10839844 0.74804688 0.2421875  0.10449219 0.71777344 0.1796875\n",
      " 0.74121094 0.72851562 0.10839844 0.28320312 0.26953125 0.50390625\n",
      " 0.34082031 0.17578125 0.13378906 0.734375   0.60253906 0.28417969\n",
      " 0.31054688 0.75       0.72558594 0.75       0.39550781 0.08984375\n",
      " 0.11230469 0.74707031 0.08691406 0.10644531 0.29296875 0.37207031\n",
      " 0.32910156 0.35839844 0.08984375 0.16699219 0.7421875  0.37695312\n",
      " 0.73535156 0.171875   0.67578125 0.55175781 0.62011719 0.35058594\n",
      " 0.14746094 0.72363281 0.75097656 0.09960938 0.75878906 0.109375\n",
      " 0.20996094 0.58886719 0.68457031 0.57519531 0.43554688 0.54785156\n",
      " 0.27832031 0.48535156 0.22558594 0.29980469 0.66601562 0.1171875\n",
      " 0.64160156 0.08789063 0.14550781 0.63085938 0.74902344 0.1015625\n",
      " 0.12988281 0.1171875  0.74609375 0.75488281 0.23730469 0.3828125\n",
      " 0.33203125 0.10351563 0.57714844 0.28710938 0.25585938 0.7421875\n",
      " 0.46484375 0.73535156 0.45800781 0.39941406 0.70019531 0.37597656\n",
      " 0.72949219 0.09667969 0.2265625  0.72851562 0.70996094 0.27246094\n",
      " 0.09277344 0.13769531 0.19238281 0.11816406 0.49414062 0.08496094\n",
      " 0.22265625 0.72460938 0.17773438 0.73535156 0.47949219 0.18457031\n",
      " 0.26660156 0.72753906 0.14648438 0.09179688 0.32910156 0.74511719\n",
      " 0.52441406 0.21777344 0.11914063 0.74511719 0.08496094 0.08007813\n",
      " 0.67382812 0.09667969 0.08789063 0.76953125 0.11816406 0.13378906\n",
      " 0.78027344 0.55273438 0.1484375  0.125      0.08691406 0.72753906\n",
      " 0.75878906 0.75097656 0.55859375 0.69824219 0.43847656 0.35546875\n",
      " 0.09375    0.65722656 0.71679688 0.65039062 0.17871094 0.625\n",
      " 0.31835938 0.10449219 0.28222656 0.76171875 0.35742188 0.56054688\n",
      " 0.74609375 0.76757812 0.18847656 0.10546875 0.08886719 0.6796875\n",
      " 0.70410156 0.40625    0.3203125  0.22949219 0.43945312 0.61523438\n",
      " 0.12792969 0.16796875 0.70117188 0.37597656 0.10449219 0.18554688\n",
      " 0.29296875 0.65820312 0.50488281 0.34277344 0.74804688 0.34179688\n",
      " 0.09570313 0.74316406 0.25390625 0.37207031 0.44140625 0.36523438\n",
      " 0.09667969 0.421875   0.74023438 0.6796875  0.68066406 0.13378906\n",
      " 0.57128906 0.19140625 0.17578125 0.10546875 0.55664062 0.17871094\n",
      " 0.08398438 0.75292969 0.22460938 0.28515625 0.109375   0.73242188\n",
      " 0.08886719 0.33691406 0.33691406 0.09179688 0.37792969 0.75683594]\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions based on the optimized weights and bias\n",
    "final_predictions = [variational_classifier(weights, bias, x) for x in Xte]\n",
    "# Get the predictions within the range 0-1 so that they represent a probability\n",
    "probability_class0 = (final_predictions-bias + np.ones(len(final_predictions)))/2\n",
    "#probability_class0 = (predictions + np.ones(len(predictions)))/2\n",
    "\n",
    "# Print the probability for each sample\n",
    "print(probability_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_class_0 = pd.DataFrame(probability_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0    0.165039\n",
      "1    0.349609\n",
      "2    0.218750\n",
      "3    0.496094\n",
      "4    0.732422\n",
      "..        ...\n",
      "295  0.336914\n",
      "296  0.336914\n",
      "297  0.091797\n",
      "298  0.377930\n",
      "299  0.756836\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(probability_class_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = pd.DataFrame((predictions, Yte), ('Predictions', 'Test')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = probability_class_0.hist(bins=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "09a2343d96e4209a5eb8971e1e9a0248c4f95d560a06ad86d050590524a525f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
