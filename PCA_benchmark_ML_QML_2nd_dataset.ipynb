{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41d3fa6-0ae0-490d-a02b-0dbf81799488",
   "metadata": {},
   "source": [
    "# Quantum benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6011e42-1fab-4f9f-ab99-f4f08607517e",
   "metadata": {},
   "source": [
    "## I - Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4f6b4-240b-4b7f-abe4-4e74b3b8cc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5492ce-4f08-4755-b4c2-efd698139101",
   "metadata": {},
   "source": [
    "## II - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90371200-0133-46ab-a205-d0f6b8858e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "#Import classical libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import functools\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "import logging\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598c94c-fdcf-41cd-a4ea-e262932c7e0f",
   "metadata": {},
   "source": [
    "## III - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e683f3b5-6021-4eb7-bc53-539a5cd79bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out CSV\n",
    "\n",
    "df = pd.read_csv('fraud_detection_bank_dataset.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf69c7f1-b10e-4b54-89ec-89dd5829ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "#EDA using Autoviz\n",
    "sweet_report = sv.analyze(df)\n",
    "\n",
    "#Saving results to HTML file\n",
    "sweet_report.show_html('sweet_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff48fa-d03b-435d-9343-67186c068b34",
   "metadata": {},
   "source": [
    "## IV - Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe1bb7-d7eb-412b-a291-bbeb654766f5",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7f6037b-3b1c-4a2c-8a9e-df1d432cafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df_labels = df['targets']\n",
    "df.drop(['targets'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "249ef3a0-7be3-4234-8be6-630db2cd267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45105d-12bb-43b3-940d-32c1c66d6b83",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0a47b2-799a-4bf7-9233-465485759b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier( random_state=42) #max_depth=2,\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fc748a-8bb9-463e-8d08-0669aa4568df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      4687\n",
      "           1       0.37      0.40      0.39      1313\n",
      "\n",
      "    accuracy                           0.72      6000\n",
      "   macro avg       0.60      0.61      0.60      6000\n",
      "weighted avg       0.73      0.72      0.73      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9e5cc-4f3f-4f4f-b575-123957b8d606",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f81c9a-552f-43de-8103-9d593cf0c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier( random_state=42) #max_depth=2,\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b409d6-e35c-4710-a1b5-89ee9a88a042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4687\n",
      "           1       0.63      0.36      0.46      1313\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.65      0.67      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report and important metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e711026-7329-4b46-b3eb-859953fcdc07",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee380ae-bb33-42f4-aae8-92feb8827a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42) #max_depth=2,\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2320684-bacb-442c-975a-9cf9039bfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4687\n",
      "           1       0.00      0.00      0.00      1313\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.69      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e47899-e42f-4daf-9a35-c2f1f4902139",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00edbaf9-55d0-49f3-afcb-fd6dcc98d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC( random_state=42) #max_depth=2,\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3d2566-a1e1-4967-925f-228f2e7d1d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4687\n",
      "           1       0.00      0.00      0.00      1313\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.69      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd918a-57d8-443f-861d-77609bdb67a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1251e3e-c8ed-4e57-a790-1fa8003f8c31",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12b4f425-f8b1-40b4-8c3f-4502a9a01a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a48d4b60-5675-473e-88a1-77dcff67374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53c4b754-1ee5-42b6-a8ec-2d9f32b5762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a948c1c2-cb55-49b2-bb4c-c2d2fdca527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=2)\n",
    "pca = PCA(n_components=2)\n",
    "pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a9e8a30-22fe-446d-b911-142649f51b00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mfeature_1\u001b[49m, feature_2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_1' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(feature_1, feature_2, '+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58737fde-c826-4acf-8c94-cb8f4df345bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_train = pca.transform(X_train)\n",
    "df_pca_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3228f8e5-9afe-4127-9b40-c70fbd78c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_train = pd.DataFrame(data = df_pca_train\n",
    "             , columns = ['pc_1', 'pc_2'])\n",
    "\n",
    "df_pca_test = pd.DataFrame(data = df_pca_test\n",
    "             , columns = ['pc_1', 'pc_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb5a4c4a-13aa-4bcc-b388-f8641146ddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37252.963487</td>\n",
       "      <td>-134.646498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-36614.757077</td>\n",
       "      <td>-134.458136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-34974.747159</td>\n",
       "      <td>-133.918582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23534.372260</td>\n",
       "      <td>-129.967247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37028.564180</td>\n",
       "      <td>-134.657561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pc_1        pc_2\n",
       "0 -37252.963487 -134.646498\n",
       "1 -36614.757077 -134.458136\n",
       "2 -34974.747159 -133.918582\n",
       "3  23534.372260 -129.967247\n",
       "4 -37028.564180 -134.657561"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141a967-8c2f-472e-a934-5ad8ac0d9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(df_pca_train.iloc[:,0], df_pca_train.iloc[:,1], 'b+')\n",
    "plt.plot(df_pca_test.iloc[:,0], df_pca_test.iloc[:,1], 'g+')\n",
    "#plt.plot(df.index, feature_2, 'g+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4b4b4e7-4a73-4323-9424-a05d62cd8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pca_1 = pd.DataFrame(feature_1)\n",
    "features_pca_2 = pd.DataFrame(feature_2)\n",
    "features_pca = features_pca_1.join(features_pca_2, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1de5099-55d4-4d2d-9ea4-eaf60c27b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_dim = len(df_pca_train.columns)\n",
    "n_dim = len(df_pca_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd626d5c-ff6a-443a-9700-10a93c24dc74",
   "metadata": {},
   "source": [
    "## Split train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afaf0912-bdbf-4460-ae4c-43016d1f5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "sample_train, sample_test, label_train, label_test = train_test_split(\n",
    "     df_pca_train, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "# Normalize\n",
    "\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Scale for better fit within the feature map\n",
    "\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Select a sample for a better control of the research and wall time\n",
    "\n",
    "train_size = 800#160\n",
    "sample_train = sample_train[:train_size]\n",
    "label_train = label_train[:train_size]\n",
    "\n",
    "test_size = 200 #40\n",
    "sample_test = sample_test[:test_size]\n",
    "label_test = label_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d815edbe-c5e7-42d6-9489-39ebb940cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters for hybrid model\n",
    "\n",
    "seed = 8500\n",
    "feature_dim = n_dim\n",
    "num_reps = 2\n",
    "num_shots =256 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bc9af-4a1c-453d-be99-d54b9e045628",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2ce7078-9255-4913-b6aa-7f05a0e077c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callable kernel classification test score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Define feature_map\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=num_reps)\n",
    "\n",
    "# Define the backend\n",
    "backend = QuantumInstance(\n",
    "    BasicAer.get_backend(\"qasm_simulator\"), shots=num_shots, seed_simulator=seed, seed_transpiler=seed\n",
    ")\n",
    "\n",
    "# Define the kernel\n",
    "\n",
    "kernel = QuantumKernel(feature_map=feature_map, quantum_instance=backend)\n",
    "\n",
    "# Model run\n",
    "svc = SVC(kernel=kernel.evaluate)\n",
    "svc.fit(sample_train, label_train)\n",
    "score = svc.score(sample_test, label_test)\n",
    "\n",
    "print(f\"Callable kernel classification test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8fd86d8-bec9-42ac-8543-c69c973a7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_predict = svc.predict(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee71fc2a-46dc-46d1-8f51-8e3df5723407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       154\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.39      0.50      0.44       200\n",
      "weighted avg       0.59      0.77      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test,result_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf51e2-5f63-4356-8aa6-381d826279b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_models = []\n",
    "_models.append(('qsvc',svc))\n",
    "_metrics = ['precision', 'recall', 'f1', 'accuracy',  'matthews_corrcoef','balanced_accuracy']\n",
    "for metric in _metrics:\n",
    "    df_results= pd.concat([df_results, evaluate_ml_model(_models, sample_train, label_train, n_fold=10, metric=metric)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357230f-6d30-41ac-b3ab-6767ab058cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1d4e4-599e-47ea-b53c-dc200ee4dec0",
   "metadata": {},
   "source": [
    "## Classical Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d93f1b24-b419-4eb0-abb5-fd297fcec137",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a92689bc-07b9-4bdd-b25c-0b0bae45a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bd332f9-cc4e-43eb-9cd9-0990b709ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ml_model(models, X, y, n_fold=10, metric='precision'):\n",
    "    \n",
    "    _df = pd.DataFrame()\n",
    "    #results = []\n",
    "    names = []\n",
    "    #scoring = 'accuracy'\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=n_fold)\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring=metric)\n",
    "        #results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        #print(msg)\n",
    "        _df =  pd.concat([_df, pd.DataFrame([round(100*cv_results.mean(), 2) , round(100*cv_results.std(), 2) ]).T])\n",
    "    _df.index = names\n",
    "    _df.columns=[metric+' mean (%)', metric+' std (%)']\n",
    "    return _df \n",
    "             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89520867-4e75-4e63-ae1e-10842771f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrics = ['precision', 'recall', 'f1', 'accuracy', 'balanced_accuracy', 'matthews_corrcoef']\n",
    "for metric in _metrics:\n",
    "    df_results= pd.concat([df_results, evaluate_ml_model(models, sample_train, label_train, n_fold=10, metric=metric)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15d5c6b3-7172-430b-b803-f60126a12cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results= pd.concat([df_results, evaluate_ml_model(models, sample_train, label_train, n_fold=10, metric='accuracy')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8561d92d-f3ee-4045-b6e5-98097a82f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision mean (%)</th>\n",
       "      <th>precision std (%)</th>\n",
       "      <th>recall mean (%)</th>\n",
       "      <th>recall std (%)</th>\n",
       "      <th>f1 mean (%)</th>\n",
       "      <th>f1 std (%)</th>\n",
       "      <th>accuracy mean (%)</th>\n",
       "      <th>accuracy std (%)</th>\n",
       "      <th>balanced_accuracy mean (%)</th>\n",
       "      <th>balanced_accuracy std (%)</th>\n",
       "      <th>matthews_corrcoef mean (%)</th>\n",
       "      <th>matthews_corrcoef std (%)</th>\n",
       "      <th>accuracy mean (%)</th>\n",
       "      <th>accuracy std (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.63</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.63</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>37.56</td>\n",
       "      <td>10.92</td>\n",
       "      <td>24.59</td>\n",
       "      <td>8.44</td>\n",
       "      <td>29.42</td>\n",
       "      <td>9.12</td>\n",
       "      <td>70.75</td>\n",
       "      <td>2.86</td>\n",
       "      <td>55.42</td>\n",
       "      <td>3.92</td>\n",
       "      <td>12.62</td>\n",
       "      <td>9.11</td>\n",
       "      <td>70.75</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>20.17</td>\n",
       "      <td>19.01</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.95</td>\n",
       "      <td>10.23</td>\n",
       "      <td>10.09</td>\n",
       "      <td>70.50</td>\n",
       "      <td>2.45</td>\n",
       "      <td>49.27</td>\n",
       "      <td>3.88</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>12.46</td>\n",
       "      <td>70.62</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>27.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>94.51</td>\n",
       "      <td>6.48</td>\n",
       "      <td>42.35</td>\n",
       "      <td>5.66</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.58</td>\n",
       "      <td>54.52</td>\n",
       "      <td>2.66</td>\n",
       "      <td>12.92</td>\n",
       "      <td>7.13</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.63</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.63</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision mean (%)  precision std (%)  recall mean (%)  recall std (%)  \\\n",
       "LR                  0.00               0.00             0.00            0.00   \n",
       "KNN                37.56              10.92            24.59            8.44   \n",
       "CART               20.17              19.01             7.01            6.95   \n",
       "NB                 27.37               4.21            94.51            6.48   \n",
       "SVM                 0.00               0.00             0.00            0.00   \n",
       "\n",
       "      f1 mean (%)  f1 std (%)  accuracy mean (%)  accuracy std (%)  \\\n",
       "LR           0.00        0.00              74.63              3.26   \n",
       "KNN         29.42        9.12              70.75              2.86   \n",
       "CART        10.23       10.09              70.50              2.45   \n",
       "NB          42.35        5.66              35.00              3.58   \n",
       "SVM          0.00        0.00              74.63              3.26   \n",
       "\n",
       "      balanced_accuracy mean (%)  balanced_accuracy std (%)  \\\n",
       "LR                         50.00                       0.00   \n",
       "KNN                        55.42                       3.92   \n",
       "CART                       49.27                       3.88   \n",
       "NB                         54.52                       2.66   \n",
       "SVM                        50.00                       0.00   \n",
       "\n",
       "      matthews_corrcoef mean (%)  matthews_corrcoef std (%)  \\\n",
       "LR                          0.00                       0.00   \n",
       "KNN                        12.62                       9.11   \n",
       "CART                       -1.55                      12.46   \n",
       "NB                         12.92                       7.13   \n",
       "SVM                         0.00                       0.00   \n",
       "\n",
       "      accuracy mean (%)  accuracy std (%)  \n",
       "LR                74.63              3.26  \n",
       "KNN               70.75              2.86  \n",
       "CART              70.62              2.32  \n",
       "NB                35.00              3.58  \n",
       "SVM               74.63              3.26  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d339da61-ed6a-4195-a0a0-7d123474e9be",
   "metadata": {},
   "source": [
    "## QSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b368ba-6fe2-4bac-ba5c-edd110015136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be assure that your qiskit version is 0.4.0\n",
    "# run !pip install --upgrade qiskit==0.4.0 if not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9afa67d9-cf2d-47a5-8fe9-affe602f79cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantumInstance' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m quantum_instance \u001b[38;5;241m=\u001b[39m QuantumInstance(backend, shots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, seed_simulator\u001b[38;5;241m=\u001b[39mseed, seed_transpiler\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Model run\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m vqc \u001b[38;5;241m=\u001b[39m \u001b[43mQSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantum_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantum_instance\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#optimizer, feature_map, var_form, training_input, test_input, datapoints[0])\u001b[39;00m\n\u001b[1;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m vqc\u001b[38;5;241m.\u001b[39mfit(sample_train, label_train)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/classifiers/qsvc.py:73\u001b[0m, in \u001b[0;36mQSVC.__init__\u001b[0;34m(self, quantum_kernel, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     71\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m algorithm_globals\u001b[38;5;241m.\u001b[39mrandom_seed\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantum_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantumInstance' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "# Define feature_map, optimizer and var_form\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=2)\n",
    "optimizer = COBYLA(maxiter=20, disp=True, rhobeg=1.0, tol=None)\n",
    "var_form = TwoLocal(feature_dim, ['ry', 'rz'], 'cz', reps=3)\n",
    "\n",
    "\n",
    "# Define the backend\n",
    "\n",
    "backend = qiskit.Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# Define the instance\n",
    "\n",
    "quantum_instance = QuantumInstance(backend, shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "\n",
    "# Model run\n",
    "vqc = QSVC(quantum_kernel=quantum_instance)#optimizer, feature_map, var_form, training_input, test_input, datapoints[0])\n",
    "\n",
    "\n",
    "result = vqc.fit(sample_train, label_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3160da18-b47b-44af-8c84-15c7f3fd30c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c31acd-2c8f-41d4-a0ec-0427af9d908b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: qiskit in /opt/homebrew/lib/python3.9/site-packages (0.37.1)\n",
      "Requirement already satisfied: qiskit-aer==0.10.4 in /opt/homebrew/lib/python3.9/site-packages (from qiskit) (0.10.4)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.19.2 in /opt/homebrew/lib/python3.9/site-packages (from qiskit) (0.19.2)\n",
      "Requirement already satisfied: qiskit-terra==0.21.1 in /opt/homebrew/lib/python3.9/site-packages (from qiskit) (0.21.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-aer==0.10.4->qiskit) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-aer==0.10.4->qiskit) (1.23.1)\n",
      "Requirement already satisfied: websocket-client>=1.0.1 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.3.3)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.26.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.8.2)\n",
      "Requirement already satisfied: websockets>=10.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (10.3)\n",
      "Requirement already satisfied: requests>=2.19 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.28.1)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.1.0)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (0.3.5.1)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (3.11)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (1.10.1)\n",
      "Requirement already satisfied: tweedledum<2.0,>=1.1 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (1.1.1)\n",
      "Requirement already satisfied: symengine>=0.9 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (0.9.2)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (4.0.0)\n",
      "Requirement already satisfied: retworkx>=0.11.0 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (0.11.0)\n",
      "Requirement already satisfied: psutil>=5 in /opt/homebrew/lib/python3.9/site-packages (from qiskit-terra==0.21.1->qiskit) (5.9.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (3.3)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=1.3 in /opt/homebrew/lib/python3.9/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (37.0.4)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from stevedore>=3.0.0->qiskit-terra==0.21.1->qiskit) (5.9.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.9/site-packages (from sympy>=1.3->qiskit-terra==0.21.1->qiskit) (1.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/homebrew/lib/python3.9/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (2.21)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade qiskit #==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70b837-4e39-4b65-83ca-8e82fc83efa1",
   "metadata": {},
   "source": [
    "## Pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1d5656-f2f2-4d96-b210-a75a161cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ec49f5-c401-4c36-aae3-57aad3eaa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = n_dim\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffcf8fdb-37a0-4b64-b73c-76be553995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "#print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49568595-37ec-4749-a230-dc4c6dae2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.09425205, requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, sample_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4febb380-0955-4f05-a872-326cc4e3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c16a1f84-63e5-4fbb-a647-cba6db4c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07412a53-c93b-4c73-bd0b-e7e144454435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bf0b58e-38f3-4c45-a4d2-3d69af787ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21ff4aa6-c15b-4a59-a718-67d8da2402dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(-0.99999959, requires_grad=True), tensor(0.10477704, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.99999897, requires_grad=True), tensor(-0.61489866, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.99627189, requires_grad=True), tensor(-0.88545579, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.99994599, requires_grad=True), tensor(-0.10680072, requires_grad=True)], Y = -1\n",
      "X = [tensor(-0.99230716, requires_grad=True), tensor(-0.14662807, requires_grad=True)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(label_train * 2 - np.ones(len(label_train)),requires_grad=True)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(sample_train, requires_grad=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "074f578a-1984-4814-9070-7b20063c8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8b4bf5c-322d-43e2-ac30-3bf83e3e7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d31d6a7-74f4-4e63-b1cb-b92bfb610a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.2941572 | f1: 0.0000000 \n",
      "Iter:     2 | Cost: 1.1195384 | f1: 0.0000000 \n",
      "Iter:     3 | Cost: 1.2232560 | f1: 0.0000000 \n",
      "Iter:     4 | Cost: 1.0813282 | f1: 0.0000000 \n",
      "Iter:     5 | Cost: 0.8904832 | f1: 0.0000000 \n",
      "Iter:     6 | Cost: 0.8329316 | f1: 0.0000000 \n",
      "Iter:     7 | Cost: 0.9425987 | f1: 0.0000000 \n",
      "Iter:     8 | Cost: 0.8166292 | f1: 0.0000000 \n",
      "Iter:     9 | Cost: 0.6325446 | f1: 0.0000000 \n",
      "Iter:    10 | Cost: 0.5580600 | f1: 0.0000000 \n",
      "Iter:    11 | Cost: 0.5505581 | f1: 0.0000000 \n",
      "Iter:    12 | Cost: 0.4913822 | f1: 0.0000000 \n",
      "Iter:    13 | Cost: 0.4594998 | f1: 0.0000000 \n",
      "New Best:\n",
      "Iter:    14 | Cost: 0.4484929 | f1: 0.5000000 \n",
      "New Best:\n",
      "Iter:    15 | Cost: 0.4705057 | f1: 0.9291339 \n",
      "New Best:\n",
      "Iter:    16 | Cost: 0.4539687 | f1: 0.9291339 \n",
      "Iter:    17 | Cost: 0.4389225 | f1: 0.9120000 \n",
      "Iter:    18 | Cost: 0.4191773 | f1: 0.8507042 \n",
      "Iter:    19 | Cost: 0.4016497 | f1: 0.6122449 \n",
      "Iter:    20 | Cost: 0.4077919 | f1: 0.3614458 \n",
      "Iter:    21 | Cost: 0.4175279 | f1: 0.1621622 \n",
      "Iter:    22 | Cost: 0.4297348 | f1: 0.0000000 \n",
      "Iter:    23 | Cost: 0.4575503 | f1: 0.0000000 \n",
      "Iter:    24 | Cost: 0.4455878 | f1: 0.0000000 \n",
      "Iter:    25 | Cost: 0.4310363 | f1: 0.0384615 \n",
      "Iter:    26 | Cost: 0.4239328 | f1: 0.4888889 \n",
      "Iter:    27 | Cost: 0.4203254 | f1: 0.4186047 \n",
      "Iter:    28 | Cost: 0.4196115 | f1: 0.2564103 \n",
      "Iter:    29 | Cost: 0.4208043 | f1: 0.1538462 \n",
      "Iter:    30 | Cost: 0.4055967 | f1: 0.4661654 \n",
      "Iter:    31 | Cost: 0.3998156 | f1: 0.5323741 \n",
      "Iter:    32 | Cost: 0.3952184 | f1: 0.6838710 \n",
      "Iter:    33 | Cost: 0.4010207 | f1: 0.8791209 \n",
      "New Best:\n",
      "Iter:    34 | Cost: 0.4227197 | f1: 0.9830508 \n",
      "New Best:\n",
      "Iter:    35 | Cost: 0.4166722 | f1: 0.9975430 \n",
      "Iter:    36 | Cost: 0.3933702 | f1: 0.8698061 \n",
      "Iter:    37 | Cost: 0.3866541 | f1: 0.6796117 \n",
      "Iter:    38 | Cost: 0.3953534 | f1: 0.4719101 \n",
      "Iter:    39 | Cost: 0.3990026 | f1: 0.4062500 \n",
      "Iter:    40 | Cost: 0.4134495 | f1: 0.1866667 \n",
      "Iter:    41 | Cost: 0.4154454 | f1: 0.1621622 \n",
      "Iter:    42 | Cost: 0.4239194 | f1: 0.0480769 \n",
      "Iter:    43 | Cost: 0.4340650 | f1: 0.0000000 \n",
      "Iter:    44 | Cost: 0.4392333 | f1: 0.0000000 \n",
      "Iter:    45 | Cost: 0.4423448 | f1: 0.0000000 \n",
      "Iter:    46 | Cost: 0.4244971 | f1: 0.0384615 \n",
      "Iter:    47 | Cost: 0.4009690 | f1: 0.3745020 \n",
      "Iter:    48 | Cost: 0.3905577 | f1: 0.7636364 \n",
      "Iter:    49 | Cost: 0.4085263 | f1: 0.9565217 \n",
      "Iter:    50 | Cost: 0.4062115 | f1: 0.9565217 \n",
      "Iter:    51 | Cost: 0.4080833 | f1: 0.9825436 \n",
      "Iter:    52 | Cost: 0.3850256 | f1: 0.8791209 \n",
      "Iter:    53 | Cost: 0.3807099 | f1: 0.8409091 \n",
      "Iter:    54 | Cost: 0.3776136 | f1: 0.7368421 \n",
      "Iter:    55 | Cost: 0.3820215 | f1: 0.5783972 \n",
      "Iter:    56 | Cost: 0.3827492 | f1: 0.5783972 \n",
      "Iter:    57 | Cost: 0.3935430 | f1: 0.4247104 \n",
      "Iter:    58 | Cost: 0.3811043 | f1: 0.6796117 \n",
      "Iter:    59 | Cost: 0.3830387 | f1: 0.8441926 \n",
      "Iter:    60 | Cost: 0.3950202 | f1: 0.9565217 \n",
      "Iter:    61 | Cost: 0.4270554 | f1: 0.9022222 \n",
      "Iter:    62 | Cost: 0.4581523 | f1: 0.8302658 \n",
      "Iter:    63 | Cost: 0.4502908 | f1: 0.8353909 \n",
      "Iter:    64 | Cost: 0.4440977 | f1: 0.8423237 \n",
      "Iter:    65 | Cost: 0.4017983 | f1: 0.9620853 \n",
      "Iter:    66 | Cost: 0.3780343 | f1: 0.8603352 \n",
      "Iter:    67 | Cost: 0.3768175 | f1: 0.6964856 \n",
      "Iter:    68 | Cost: 0.3766676 | f1: 0.7560976 \n",
      "Iter:    69 | Cost: 0.3775613 | f1: 0.7928994 \n",
      "Iter:    70 | Cost: 0.3818528 | f1: 0.8852459 \n",
      "Iter:    71 | Cost: 0.3804096 | f1: 0.8791209 \n",
      "Iter:    72 | Cost: 0.3779977 | f1: 0.8474576 \n",
      "Iter:    73 | Cost: 0.3815807 | f1: 0.9002695 \n",
      "Iter:    74 | Cost: 0.3916361 | f1: 0.9722922 \n",
      "Iter:    75 | Cost: 0.4066413 | f1: 0.9463869 \n",
      "Iter:    76 | Cost: 0.4156479 | f1: 0.9164786 \n",
      "Iter:    77 | Cost: 0.4060314 | f1: 0.9463869 \n",
      "Iter:    78 | Cost: 0.3794137 | f1: 0.8972973 \n",
      "Iter:    79 | Cost: 0.3747250 | f1: 0.6881029 \n",
      "Iter:    80 | Cost: 0.3954817 | f1: 0.3745020 \n",
      "Iter:    81 | Cost: 0.4148579 | f1: 0.1621622 \n",
      "Iter:    82 | Cost: 0.4500498 | f1: 0.0000000 \n",
      "Iter:    83 | Cost: 0.5098796 | f1: 0.0000000 \n",
      "Iter:    84 | Cost: 0.5730887 | f1: 0.0000000 \n",
      "Iter:    85 | Cost: 0.5351877 | f1: 0.0000000 \n",
      "Iter:    86 | Cost: 0.4907288 | f1: 0.0000000 \n",
      "Iter:    87 | Cost: 0.4115004 | f1: 0.2105263 \n",
      "Iter:    88 | Cost: 0.3773264 | f1: 0.7636364 \n",
      "Iter:    89 | Cost: 0.3925106 | f1: 0.9484536 \n",
      "Iter:    90 | Cost: 0.4157340 | f1: 0.9598109 \n",
      "Iter:    91 | Cost: 0.4165330 | f1: 0.9643705 \n",
      "Iter:    92 | Cost: 0.4089370 | f1: 0.9670886 \n",
      "Iter:    93 | Cost: 0.3997403 | f1: 0.8972973 \n",
      "Iter:    94 | Cost: 0.3922697 | f1: 0.6838710 \n",
      "Iter:    95 | Cost: 0.3923356 | f1: 0.5734266 \n",
      "Iter:    96 | Cost: 0.3873140 | f1: 0.6534653 \n",
      "Iter:    97 | Cost: 0.3834569 | f1: 0.7928994 \n",
      "Iter:    98 | Cost: 0.3829708 | f1: 0.8635097 \n",
      "Iter:    99 | Cost: 0.3834999 | f1: 0.9032258 \n",
      "Iter:   100 | Cost: 0.3861651 | f1: 0.9511568 \n",
      "Iter:   101 | Cost: 0.3810027 | f1: 0.9120000 \n",
      "Iter:   102 | Cost: 0.3741309 | f1: 0.8035191 \n",
      "Iter:   103 | Cost: 0.3751181 | f1: 0.8104956 \n",
      "Iter:   104 | Cost: 0.3761708 | f1: 0.7928994 \n",
      "Iter:   105 | Cost: 0.3770360 | f1: 0.7560976 \n",
      "Iter:   106 | Cost: 0.3810805 | f1: 0.6169492 \n",
      "Iter:   107 | Cost: 0.3916273 | f1: 0.4661654 \n",
      "Iter:   108 | Cost: 0.3896084 | f1: 0.4888889 \n",
      "Iter:   109 | Cost: 0.3865017 | f1: 0.5217391 \n",
      "Iter:   110 | Cost: 0.4054331 | f1: 0.2857143 \n",
      "Iter:   111 | Cost: 0.3879467 | f1: 0.4888889 \n",
      "Iter:   112 | Cost: 0.3758588 | f1: 0.7006369 \n",
      "Iter:   113 | Cost: 0.3753345 | f1: 0.8376068 \n",
      "Iter:   114 | Cost: 0.3781659 | f1: 0.8913043 \n",
      "Iter:   115 | Cost: 0.3889167 | f1: 0.9696970 \n",
      "Iter:   116 | Cost: 0.4338472 | f1: 0.8565401 \n",
      "Iter:   117 | Cost: 0.4623283 | f1: 0.8185484 \n",
      "Iter:   118 | Cost: 0.4174667 | f1: 0.9164786 \n",
      "Iter:   119 | Cost: 0.3816828 | f1: 0.8972973 \n",
      "Iter:   120 | Cost: 0.3785991 | f1: 0.6838710 \n",
      "Iter:   121 | Cost: 0.3815614 | f1: 0.6216216 \n",
      "Iter:   122 | Cost: 0.3813329 | f1: 0.6838710 \n",
      "Iter:   123 | Cost: 0.3830161 | f1: 0.8242075 \n",
      "Iter:   124 | Cost: 0.3915814 | f1: 0.9263158 \n",
      "Iter:   125 | Cost: 0.4327088 | f1: 0.8806941 \n",
      "Iter:   126 | Cost: 0.4502827 | f1: 0.8388430 \n",
      "Iter:   127 | Cost: 0.4368788 | f1: 0.8529412 \n",
      "Iter:   128 | Cost: 0.4001541 | f1: 0.9759615 \n",
      "Iter:   129 | Cost: 0.3763727 | f1: 0.7928994 \n",
      "Iter:   130 | Cost: 0.3858000 | f1: 0.5217391 \n",
      "Iter:   131 | Cost: 0.4170556 | f1: 0.1538462 \n",
      "Iter:   132 | Cost: 0.4375280 | f1: 0.0000000 \n",
      "Iter:   133 | Cost: 0.4526124 | f1: 0.0000000 \n",
      "Iter:   134 | Cost: 0.4477770 | f1: 0.0000000 \n",
      "Iter:   135 | Cost: 0.4632359 | f1: 0.0000000 \n",
      "Iter:   136 | Cost: 0.4721993 | f1: 0.0000000 \n",
      "Iter:   137 | Cost: 0.4529160 | f1: 0.0000000 \n",
      "Iter:   138 | Cost: 0.4135482 | f1: 0.3223140 \n",
      "Iter:   139 | Cost: 0.4083216 | f1: 0.4503817 \n",
      "Iter:   140 | Cost: 0.4046444 | f1: 0.5323741 \n",
      "Iter:   141 | Cost: 0.4153695 | f1: 0.8441926 \n",
      "Iter:   142 | Cost: 0.4193761 | f1: 0.9263158 \n",
      "Iter:   143 | Cost: 0.4122106 | f1: 0.9457364 \n",
      "Iter:   144 | Cost: 0.3918428 | f1: 0.8635097 \n",
      "Iter:   145 | Cost: 0.3803284 | f1: 0.7484663 \n",
      "Iter:   146 | Cost: 0.3790789 | f1: 0.8242075 \n",
      "Iter:   147 | Cost: 0.3804140 | f1: 0.8852459 \n",
      "Iter:   148 | Cost: 0.3855739 | f1: 0.9457364 \n",
      "Iter:   149 | Cost: 0.3808278 | f1: 0.8913043 \n",
      "Iter:   150 | Cost: 0.3799046 | f1: 0.8635097 \n",
      "Iter:   151 | Cost: 0.3808015 | f1: 0.8603352 \n",
      "Iter:   152 | Cost: 0.3877115 | f1: 0.9263158 \n",
      "Iter:   153 | Cost: 0.4121029 | f1: 0.9419954 \n",
      "Iter:   154 | Cost: 0.4092137 | f1: 0.9598109 \n",
      "Iter:   155 | Cost: 0.3986098 | f1: 0.9876543 \n",
      "Iter:   156 | Cost: 0.3818354 | f1: 0.8913043 \n",
      "Iter:   157 | Cost: 0.3791154 | f1: 0.8698061 \n",
      "Iter:   158 | Cost: 0.3760871 | f1: 0.8208092 \n",
      "Iter:   159 | Cost: 0.3750188 | f1: 0.7560976 \n",
      "Iter:   160 | Cost: 0.3755464 | f1: 0.6964856 \n",
      "Iter:   161 | Cost: 0.3760064 | f1: 0.6838710 \n",
      "Iter:   162 | Cost: 0.3758114 | f1: 0.6923077 \n",
      "Iter:   163 | Cost: 0.3754446 | f1: 0.7560976 \n",
      "Iter:   164 | Cost: 0.3768996 | f1: 0.8208092 \n",
      "Iter:   165 | Cost: 0.3878379 | f1: 0.9457364 \n",
      "Iter:   166 | Cost: 0.3983284 | f1: 0.9925926 \n",
      "Iter:   167 | Cost: 0.4037273 | f1: 0.9643705 \n",
      "Iter:   168 | Cost: 0.3923697 | f1: 0.9748744 \n",
      "Iter:   169 | Cost: 0.3750296 | f1: 0.8474576 \n",
      "Iter:   170 | Cost: 0.3749084 | f1: 0.6710098 \n",
      "Iter:   171 | Cost: 0.3831209 | f1: 0.5270758 \n",
      "Iter:   172 | Cost: 0.3959588 | f1: 0.3745020 \n",
      "Iter:   173 | Cost: 0.4075073 | f1: 0.2413793 \n",
      "Iter:   174 | Cost: 0.4054749 | f1: 0.2857143 \n",
      "Iter:   175 | Cost: 0.3807183 | f1: 0.6122449 \n",
      "Iter:   176 | Cost: 0.3778938 | f1: 0.8035191 \n",
      "Iter:   177 | Cost: 0.3818567 | f1: 0.8852459 \n",
      "Iter:   178 | Cost: 0.3897738 | f1: 0.9538462 \n",
      "Iter:   179 | Cost: 0.3865663 | f1: 0.9263158 \n",
      "Iter:   180 | Cost: 0.3868050 | f1: 0.9263158 \n",
      "Iter:   181 | Cost: 0.3917194 | f1: 0.9565217 \n",
      "Iter:   182 | Cost: 0.3914304 | f1: 0.9565217 \n",
      "Iter:   183 | Cost: 0.3793579 | f1: 0.8242075 \n",
      "Iter:   184 | Cost: 0.3809371 | f1: 0.6308725 \n",
      "Iter:   185 | Cost: 0.4017298 | f1: 0.3278689 \n",
      "Iter:   186 | Cost: 0.4169427 | f1: 0.1538462 \n",
      "Iter:   187 | Cost: 0.4328303 | f1: 0.0000000 \n",
      "Iter:   188 | Cost: 0.4179653 | f1: 0.1454545 \n",
      "Iter:   189 | Cost: 0.4142639 | f1: 0.1621622 \n",
      "Iter:   190 | Cost: 0.3795435 | f1: 0.6838710 \n",
      "Iter:   191 | Cost: 0.3869718 | f1: 0.8791209 \n",
      "Iter:   192 | Cost: 0.3884571 | f1: 0.8666667 \n",
      "Iter:   193 | Cost: 0.3872237 | f1: 0.8376068 \n",
      "Iter:   194 | Cost: 0.3840141 | f1: 0.6964856 \n",
      "Iter:   195 | Cost: 0.3824590 | f1: 0.7368421 \n",
      "Iter:   196 | Cost: 0.3833460 | f1: 0.6400000 \n",
      "Iter:   197 | Cost: 0.3849298 | f1: 0.5684211 \n",
      "Iter:   198 | Cost: 0.3889908 | f1: 0.5109489 \n",
      "Iter:   199 | Cost: 0.3954157 | f1: 0.4186047 \n",
      "Iter:   200 | Cost: 0.4120042 | f1: 0.2105263 \n",
      "Iter:   201 | Cost: 0.4078099 | f1: 0.2564103 \n",
      "Iter:   202 | Cost: 0.3835639 | f1: 0.7289720 \n",
      "Iter:   203 | Cost: 0.3931466 | f1: 0.9177719 \n",
      "Iter:   204 | Cost: 0.4034442 | f1: 0.9876543 \n",
      "Iter:   205 | Cost: 0.3817034 | f1: 0.8852459 \n",
      "Iter:   206 | Cost: 0.3749424 | f1: 0.7006369 \n",
      "Iter:   207 | Cost: 0.3816336 | f1: 0.5531915 \n",
      "Iter:   208 | Cost: 0.3837396 | f1: 0.5323741 \n",
      "Iter:   209 | Cost: 0.3794300 | f1: 0.6169492 \n",
      "Iter:   210 | Cost: 0.3775922 | f1: 0.7636364 \n",
      "Iter:   211 | Cost: 0.3846404 | f1: 0.8913043 \n",
      "Iter:   212 | Cost: 0.3857573 | f1: 0.8972973 \n",
      "Iter:   213 | Cost: 0.3802865 | f1: 0.8242075 \n",
      "Iter:   214 | Cost: 0.3777221 | f1: 0.7636364 \n",
      "Iter:   215 | Cost: 0.3770769 | f1: 0.8000000 \n",
      "Iter:   216 | Cost: 0.3792833 | f1: 0.8821918 \n",
      "Iter:   217 | Cost: 0.3768627 | f1: 0.8603352 \n",
      "Iter:   218 | Cost: 0.3804457 | f1: 0.9120000 \n",
      "Iter:   219 | Cost: 0.3808508 | f1: 0.9234828 \n",
      "Iter:   220 | Cost: 0.3731633 | f1: 0.8035191 \n",
      "Iter:   221 | Cost: 0.3766326 | f1: 0.6262626 \n",
      "Iter:   222 | Cost: 0.3870131 | f1: 0.4888889 \n",
      "Iter:   223 | Cost: 0.3882090 | f1: 0.4719101 \n",
      "Iter:   224 | Cost: 0.3813788 | f1: 0.5531915 \n",
      "Iter:   225 | Cost: 0.3774831 | f1: 0.6400000 \n",
      "Iter:   226 | Cost: 0.3752245 | f1: 0.7289720 \n",
      "Iter:   227 | Cost: 0.3759476 | f1: 0.8104956 \n",
      "Iter:   228 | Cost: 0.3762453 | f1: 0.8208092 \n",
      "Iter:   229 | Cost: 0.3750147 | f1: 0.7893175 \n",
      "Iter:   230 | Cost: 0.3746677 | f1: 0.7169811 \n",
      "Iter:   231 | Cost: 0.3756205 | f1: 0.6666667 \n",
      "Iter:   232 | Cost: 0.3740147 | f1: 0.7169811 \n",
      "Iter:   233 | Cost: 0.3741792 | f1: 0.6923077 \n",
      "Iter:   234 | Cost: 0.3743775 | f1: 0.6838710 \n",
      "Iter:   235 | Cost: 0.3735357 | f1: 0.7006369 \n",
      "Iter:   236 | Cost: 0.3730395 | f1: 0.8000000 \n",
      "Iter:   237 | Cost: 0.3781884 | f1: 0.8972973 \n",
      "Iter:   238 | Cost: 0.3936350 | f1: 0.9950980 \n",
      "Iter:   239 | Cost: 0.4160958 | f1: 0.9103139 \n",
      "Iter:   240 | Cost: 0.4352065 | f1: 0.8511530 \n",
      "Iter:   241 | Cost: 0.4456402 | f1: 0.8336756 \n",
      "Iter:   242 | Cost: 0.4263624 | f1: 0.8731183 \n",
      "Iter:   243 | Cost: 0.3894141 | f1: 0.9748744 \n",
      "Iter:   244 | Cost: 0.3734598 | f1: 0.7928994 \n",
      "Iter:   245 | Cost: 0.3851660 | f1: 0.5000000 \n",
      "Iter:   246 | Cost: 0.4099910 | f1: 0.2183406 \n",
      "Iter:   247 | Cost: 0.4274213 | f1: 0.0289855 \n",
      "Iter:   248 | Cost: 0.4323283 | f1: 0.0000000 \n",
      "Iter:   249 | Cost: 0.4381261 | f1: 0.0000000 \n",
      "Iter:   250 | Cost: 0.4292450 | f1: 0.0000000 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "ccost = 0 \n",
    "for it in range(250):\n",
    "\n",
    "    # weights update by one optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    '''if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )'''\n",
    "    prec = metrics.f1_score(Y, predictions, average='binary', pos_label=1)\n",
    "    if  prec > abest or ((prec == abest) and (cost(weights, bias, X, Y) < ccost)):\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = prec\n",
    "        ccost = cost(weights, bias, X, Y)\n",
    "        print(\"New Best:\")\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | f1: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), prec\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee2dceeb-5b76-4ec7-9ebb-efb9e562cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(label_test * 2 - np.ones(len(label_test)))\n",
    "Xte = np.array(normalize(sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4416ed73-4c7d-44e3-a539-9dba3191327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.4108641428769529, Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d2c6851-a0ea-4637-9f25-22a4a0b80c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       154\n",
      "         1.0       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4a2955a-d877-4885-ad84-5f31458a7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.72      0.79      0.76       141\n",
      "         1.0       0.36      0.27      0.31        59\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.54      0.53      0.53       200\n",
      "weighted avg       0.61      0.64      0.62       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcedeada-a82f-4e82-b738-6a862dc801c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precision: 100.0%\n",
      "    Recall: 100.0%\n",
      "    f1: 100.0%\n",
      "    Accuracy: 100.0%\n",
      "    Balanced accuracy: 100.0%\n",
      "    Matthew corcorref: 100.0%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "\n",
    "    Precision: {round(100*metrics.precision_score(predictions,Yte),2)}%\n",
    "    Recall: {round(100*metrics.recall_score(predictions,Yte),2)}%\n",
    "    f1: {round(100*metrics.f1_score(predictions,Yte),2)}%\n",
    "    Accuracy: {round(100*metrics.accuracy_score(predictions,Yte),2)}%\n",
    "    Balanced accuracy: {round(100*metrics.balanced_accuracy_score(predictions,Yte),2)}%\n",
    "    Matthew corcorref: {round(100*metrics.matthews_corrcoef(predictions,Yte),2)}%\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5308be-6630-4637-a387-b4f796aeb98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
